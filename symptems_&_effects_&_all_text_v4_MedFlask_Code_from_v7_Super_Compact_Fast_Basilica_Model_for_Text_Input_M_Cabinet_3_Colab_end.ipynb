{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "symptems & effects & all_text v4 MedFlask Code from v7 Super_Compact Fast Basilica Model for Text_Input M_Cabinet_3 Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlZE0rDluVJk",
        "colab_type": "code",
        "outputId": "f4e5540d-3cec-41e0-cfc9-b1a21810091d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "# install basilica\n",
        "!pip install basilica"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting basilica\n",
            "  Downloading https://files.pythonhosted.org/packages/68/19/6216f1c0ad6d0f738bd1061cb5c65097021b41f3891046fac87bc4c4e1ae/basilica-0.2.8.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from basilica) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from basilica) (1.12.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from basilica) (6.2.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (2019.11.28)\n",
            "Building wheels for collected packages: basilica\n",
            "  Building wheel for basilica (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basilica: filename=basilica-0.2.8-cp36-none-any.whl size=4710 sha256=4f63d72cd9c46bec3139662f0f4a6861d8dcef94b8ba69ec66ea8e9b728759f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/18/9f/46f6face8baf98e31b52bf91a0d76930ec76860f9e9211104d\n",
            "Successfully built basilica\n",
            "Installing collected packages: basilica\n",
            "Successfully installed basilica-0.2.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUoQFjQR1h3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import The Libraries & Packages\n",
        "import basilica\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import spatial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wfb-5C6TEUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# user input\n",
        "user_input = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i17xe7qKMj3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# user input for effects search\n",
        "user_input_effects = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3SGG9daMkAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# user input for symptoms search\n",
        "user_input_symptoms = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spQ3xrouWYS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_input_all_text = \"appetite, depression, Tingly, Creative, Hungry, Relaxed, Uplifted, Apricot, Citrus, Grapefruit\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0OXthCnWmT-",
        "colab_type": "code",
        "outputId": "722cb5be-3b50-40b8-adee-25a16efd0bf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# download the data into the current working directory/folder\n",
        "!wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-08 17:51:40--  https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1267451 (1.2M) [text/plain]\n",
            "Saving to: ‘med1.csv’\n",
            "\n",
            "\rmed1.csv              0%[                    ]       0  --.-KB/s               \rmed1.csv            100%[===================>]   1.21M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-01-08 17:51:40 (26.7 MB/s) - ‘med1.csv’ saved [1267451/1267451]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tAkYE5-2Cuv",
        "colab_type": "code",
        "outputId": "9d53000d-9367-42be-f54d-c7feca034cb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "# get pickled trained embeddings for med cultivars\n",
        "!wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-08 17:51:41--  https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/lineality/4.4_Build_files/master/medembedv2.pkl [following]\n",
            "--2020-01-08 17:51:41--  https://raw.githubusercontent.com/lineality/4.4_Build_files/master/medembedv2.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16288303 (16M) [application/octet-stream]\n",
            "Saving to: ‘medembedv2.pkl’\n",
            "\n",
            "medembedv2.pkl      100%[===================>]  15.53M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-01-08 17:51:41 (153 MB/s) - ‘medembedv2.pkl’ saved [16288303/16288303]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCVPh8Sf16aP",
        "colab_type": "code",
        "outputId": "35786da4-6ede-4c00-e4a6-1c05be560743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "# improved dataframe with medical terms\n",
        "!wget https://github.com/lineality/4.4_Build_files/raw/master/symptoms8_medcab3.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-08 22:51:08--  https://github.com/lineality/4.4_Build_files/raw/master/symptoms8_medcab3.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/lineality/4.4_Build_files/master/symptoms8_medcab3.csv [following]\n",
            "--2020-01-08 22:51:08--  https://raw.githubusercontent.com/lineality/4.4_Build_files/master/symptoms8_medcab3.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1497841 (1.4M) [text/plain]\n",
            "Saving to: ‘symptoms8_medcab3.csv’\n",
            "\n",
            "symptoms8_medcab3.c 100%[===================>]   1.43M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-01-08 22:51:08 (27.4 MB/s) - ‘symptoms8_medcab3.csv’ saved [1497841/1497841]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7lzD6jG1YMz",
        "colab_type": "code",
        "outputId": "82b1b56e-0cc6-446a-cda0-ca2d4df64438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "# get pickled trained embeddings for symptoms med cultivars\n",
        "!wget https://github.com/lineality/4.4_Build_files/raw/master/symptommedembedv6.pkl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-08 17:51:43--  https://github.com/lineality/4.4_Build_files/raw/master/symptommedembedv6.pkl\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/lineality/4.4_Build_files/master/symptommedembedv6.pkl [following]\n",
            "--2020-01-08 17:51:44--  https://raw.githubusercontent.com/lineality/4.4_Build_files/master/symptommedembedv6.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16288303 (16M) [application/octet-stream]\n",
            "Saving to: ‘symptommedembedv6.pkl’\n",
            "\n",
            "symptommedembedv6.p 100%[===================>]  15.53M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-01-08 17:51:44 (153 MB/s) - ‘symptommedembedv6.pkl’ saved [16288303/16288303]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPUpWY6EWhU_",
        "colab_type": "code",
        "outputId": "99ac2904-1931-4a49-e4e7-4e898633aa9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "# get pickled trained embeddings for symptoms med cultivars\n",
        "!wget https://github.com/lineality/4.4_Build_files/raw/master/all_text_medembedv8.pkl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-08 22:51:25--  https://github.com/lineality/4.4_Build_files/raw/master/all_text_medembedv8.pkl\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/lineality/4.4_Build_files/master/all_text_medembedv8.pkl [following]\n",
            "--2020-01-08 22:51:25--  https://raw.githubusercontent.com/lineality/4.4_Build_files/master/all_text_medembedv8.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16288303 (16M) [application/octet-stream]\n",
            "Saving to: ‘all_text_medembedv8.pkl’\n",
            "\n",
            "all_text_medembedv8 100%[===================>]  15.53M  42.5MB/s    in 0.4s    \n",
            "\n",
            "2020-01-08 22:51:26 (42.5 MB/s) - ‘all_text_medembedv8.pkl’ saved [16288303/16288303]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az7sYKS82MXC",
        "colab_type": "code",
        "outputId": "05ffad2c-491f-4c6f-81e2-9e1d514cbdc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIgTJzih1r6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# old version\n",
        "# put the data into a dataframe named df\n",
        "#df = pd.read_csv('med1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNqSzEuw2W97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# put the symptoms data into a dataframe named df\n",
        "df = pd.read_csv('symptoms8_medcab3.csv')\n",
        "\n",
        "# df2 not needed...just one df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKDjJB0-ytDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#effcts unpickling file of embedded cultivar descriptions\n",
        "unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yJybjnUd3_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkUubkSG1RKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unpickling file of embedded cultivar symptoms diseases\n",
        "unpickled_df_test = pd.read_pickle(\"./symptommedembedv7.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnVfK3GrW5gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unpickling file of embedded cultivar symptoms diseases\n",
        "unpickled_df_test = pd.read_pickle(\"./all_text_medembedv8.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0Ah87WuWXIq",
        "colab_type": "text"
      },
      "source": [
        "# Effects Version where everything happens in one \"predict\" function\n",
        "## string ouput"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-asun6GZCvb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# user input\n",
        "user_input = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "\n",
        "\n",
        "def predict(user_input):\n",
        "\n",
        "  #effcts unpickling file of embedded cultivar descriptions\n",
        "  unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "  # getting data\n",
        "  df = pd.read_csv('symptoms8_medcab3.csv')\n",
        "\n",
        "  # Part 1\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "\n",
        "  # Part 4: returns all data for the top 5 results as a json obj\n",
        "  df_big_json = df.sort_values(by='score', ascending=False)\n",
        "  df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "  df_big_json = df_big_json[:5]\n",
        "  #df_big_json = df_big_json.to_json(orient='columns')\n",
        "  string1 = df_big_json['Strain'].values\n",
        "  string1 = str(string1)\n",
        "  string1\n",
        "\n",
        "  # Part 5: output\n",
        "  return string1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhA7-T7rUGzN",
        "colab_type": "code",
        "outputId": "64dca2e6-b61c-4ca3-8df4-ade66a36f1ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predict(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['98-White-Widow' 'Purple-Diesel' 'Blue-Monster' 'Deadhead-Og' 'Kali-Dog']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lvnCxB_-NkYx"
      },
      "source": [
        "# Symptoms Version where everything happens in one \"predict\" function\n",
        "## string output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WCYVso-RNkYz",
        "outputId": "bcf73149-b228-4b45-816a-e649ebcec4a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# user input\n",
        "user_input = \"multiple sclerosis, epilepsy, pain, \"\n",
        "\n",
        "def predict_symptoms(user_input):\n",
        "\n",
        "  #unpickling file of embedded cultivar symptoms diseases\n",
        "  unpickled_df_test = pd.read_pickle(\"./symptommedembedv6.pkl\")\n",
        "\n",
        "  # getting data\n",
        "  df = pd.read_csv('symptoms6_medcab3.csv')\n",
        "\n",
        "  # Part 1\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "\n",
        "  # Part 4: returns all data for the top 5 results as a json obj\n",
        "  df_big_json = df.sort_values(by='score', ascending=False)\n",
        "  df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "  df_big_json = df_big_json[:5]\n",
        "  #df_big_json = df_big_json.to_json(orient='columns')\n",
        "  string1 = df_big_json['Strain'].values\n",
        "  string1 = str(string1)\n",
        "  string1\n",
        "\n",
        "  # Part 5: output\n",
        "  return string1\n",
        "\n",
        "'''\n",
        "  # Part 4\n",
        "  output = df['Strain'].groupby(df['score']).value_counts().nlargest(5, keep='last')\n",
        "  output_string = str(output)\n",
        "\n",
        "\n",
        "  # Part 5: the output\n",
        "  return output_string\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n  # Part 4\\n  output = df['Strain'].groupby(df['score']).value_counts().nlargest(5, keep='last')\\n  output_string = str(output)\\n\\n\\n  # Part 5: the output\\n  return output_string\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b38f2d49-b2dc-440e-ff79-757dba8490bb",
        "id": "JC_xTaHTNkY1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predict_symptoms(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['Acdc' 'Omega-Dawg' 'White-Lightning' 'Dream-Star' 'Sour-Power']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j423A7uNgqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJRtTWBIGj_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k8hCWNUddw_j"
      },
      "source": [
        "# Effects Version where everything happens in one \"predict\" function\n",
        "## json output "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gVxvVEPXdw_m",
        "colab": {}
      },
      "source": [
        "# user input\n",
        "user_input = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "\n",
        "\n",
        "def predict(user_input):\n",
        "\n",
        "  # getting data\n",
        "  df = pd.read_csv('symptoms6_medcab3.csv')\n",
        "\n",
        "  #effcts unpickling file of embedded cultivar descriptions\n",
        "  unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "  # Part 1\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "  # Part 4: returns all data for the top 5 results as a json obj\n",
        "  df_big_json = df.sort_values(by='score', ascending=False)\n",
        "  df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "  df_big_json = df_big_json[:5]\n",
        "  df_big_json = df_big_json.to_json(orient='columns')\n",
        "\n",
        "  # Part 5: output\n",
        "  return df_big_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "af3127e6-b180-417f-bbe9-9bcc23a8b962",
        "id": "qb88I-tbdw_s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "predict(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Strain\":{\"1\":\"98-White-Widow\",\"1682\":\"Purple-Diesel\",\"304\":\"Blue-Monster\",\"644\":\"Deadhead-Og\",\"1163\":\"Kali-Dog\"},\"Type\":{\"1\":\"hybrid\",\"1682\":\"hybrid\",\"304\":\"indica\",\"644\":\"hybrid\",\"1163\":\"hybrid\"},\"Rating\":{\"1\":4.7,\"1682\":4.2,\"304\":4.7,\"644\":4.4,\"1163\":4.8},\"Effects\":{\"1\":\"Relaxed,Aroused,Creative,Happy,Energetic\",\"1682\":\"Relaxed,Uplifted,Happy,Energetic,Focused\",\"304\":\"Relaxed,Hungry,Talkative,Sleepy,Happy\",\"644\":\"Uplifted,Relaxed,Happy,Euphoric,Creative\",\"1163\":\"Relaxed,Uplifted,Happy,Focused,Energetic\"},\"Flavor\":{\"1\":\"Flowery,Violet,Diesel\",\"1682\":\"Sweet,Berry,Diesel\",\"304\":\"Berry,Sweet,Diesel\",\"644\":\"Earthy,Pine,Diesel\",\"1163\":\"Citrus,Lemon,Diesel\"},\"Description\":{\"1\":\"The \\\\u201898 Aloha White Widow is an especially potent cut of White Widow that has grown in renown alongside Hawaiian legends like Maui Wowie and Kona Gold. This White Widow phenotype reeks of diesel and skunk and has a rich earthy taste with intermittent notes of hash. Its buds are coated in trichomes, giving its dark foliage a lustrous glint to go along with its room-filling odor. This one-hitter-quitter uplifts the mind with mind-bending euphoria that materializes in the body as airy relaxation. \\\\u201898 Aloha White Widow is available from Pua Mana 1st Hawaiian Pakal\\\\u014dl\\\\u014d Seed Bank. \\\\u00a0\",\"1682\":\"Purple Diesel, bred by Cali Connection, is a wonder among hybrid strains. While most of the effects are similar to traditional sativas (energizing, uplifting, focused), Purple D is also an exceptional strain for pain relief. A sneaky cross between Pre-98 Bubba Kush\\\\u00a0and Sour Diesel, this strain takes a while to fully kick in. However, once the effects begin to present themselves, users are struck by a type of giggly, euphoric bliss. A favorite among daytime users, Purple Diesel features a sour, fuel-like aroma. For those interested in growing, this strain has an early flowering time of around 8 weeks and features dense buds with deep purple leaves.\",\"304\":\"Blue Monster is a powerful combination of G13, Blueberry, Northern Lights #5, and a Mexican landrace strain. Bred by Goldenseed, Blue Monster combines a sweet mix of flavors with strong indica effects. Its complex aroma of berries and tropical fruits exposes the influence of Blueberry and G13 genetics. When grown to its full potential, the forceful relaxation of Blue Monster can overwhelm novices with its immediate body sedation and commanding cerebral effects. This monster indica is sure to scare away sleepless nights and body pains.\",\"644\":\"A modern West Coast classic, Deadhead OG was created by master breeder Skunk VA of Cali Connection Seeds by crossing two already legendary strains, Chemdawg 91 and the SFV OG Kush. \\\\u00a0Known as a very hearty and pungent strain, most phenotypes present an earthy, piney smell and taste, though some can lean more to the diesel aromas of the SFV. \\\\u00a0As a cross of two very potent strains, Deadhead OG regularly reaches THC levels over 20%. \\\\u00a0Most users describe the high as cerebral and stimulating but with a relaxed body feel.\",\"1163\":\"This OG Kush and Sour Diesel hybrid from Royal Queen Seeds is a powerful strain that has an overwhelming aroma of lemons and diesel fuel. Kali Dog is a sativa-dominant cross but a heavy influence from the indica genetics gives this strain a balanced effect that is described as uplifting, relaxing, and cerebral.\"},\"symptoms_diseases\":{\"1\":\" \",\"1682\":\"ms, pain, \",\"304\":\"pain, \",\"644\":\" \",\"1163\":\" \"},\"score\":{\"1\":0.9835731748,\"1682\":0.9698372559,\"304\":0.9641033337,\"644\":0.9629495883,\"1163\":0.9617265437}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "obZxVy5Gdw_w"
      },
      "source": [
        "# Symptoms Version where everything happens in one \"predict\" function\n",
        "## json output "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vHE0z6ffdw_x",
        "colab": {}
      },
      "source": [
        "# user input\n",
        "user_input = \"multiple sclerosis, epilepsy, pain, \"\n",
        "\n",
        "def predict_symptoms(user_input):\n",
        "\n",
        "  #unpickling file of embedded cultivar symptoms diseases\n",
        "  unpickled_df_test = pd.read_pickle(\"./symptommedembedv6.pkl\")\n",
        "\n",
        "  # getting data\n",
        "  df = pd.read_csv('symptoms6_medcab3.csv')\n",
        "\n",
        "  # Part 1\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "\n",
        "  # Part 4: returns all data for the top 5 results as a json obj\n",
        "  df_big_json = df.sort_values(by='score', ascending=False)\n",
        "  df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "  df_big_json = df_big_json[:5]\n",
        "  df_big_json = df_big_json.to_json(orient='columns')\n",
        "\n",
        "  # Part 5: output\n",
        "  return df_big_json\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "799ddeb8-a7d6-4964-f826-39921e3a194e",
        "id": "SVTPamDBdw_0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "predict_symptoms(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Strain\":{\"22\":\"Acdc\",\"1517\":\"Omega-Dawg\",\"2290\":\"White-Lightning\",\"711\":\"Dream-Star\",\"1951\":\"Sour-Power\"},\"Type\":{\"22\":\"hybrid\",\"1517\":\"hybrid\",\"2290\":\"hybrid\",\"711\":\"hybrid\",\"1951\":\"hybrid\"},\"Rating\":{\"22\":4.5,\"1517\":4.4,\"2290\":4.4,\"711\":4.8,\"1951\":4.7},\"Effects\":{\"22\":\"Relaxed,Happy,Uplifted,Focused,Euphoric\",\"1517\":\"Uplifted,Euphoric,Relaxed,Happy,Tingly\",\"2290\":\"Happy,Giggly,Uplifted,Euphoric,Relaxed\",\"711\":\"Euphoric,Creative,Uplifted,Talkative,Relaxed\",\"1951\":\"Happy,Euphoric,Energetic,Talkative,Hungry\"},\"Flavor\":{\"22\":\"Earthy,Pine,Woody\",\"1517\":\"Diesel,Sweet,Earthy\",\"2290\":\"Sweet,Skunk,Pungent\",\"711\":\"Earthy,Woody,Sweet\",\"1951\":\"Diesel,Skunk,Pungent\"},\"Description\":{\"22\":\"ACDC is\\\\u00a0a sativa-dominant phenotype of the high-CBD\\\\u00a0cannabis strain, Cannatonic. One remarkable characteristic of ACDC is its THC:CBD ratio of 1:20, meaning this strain induces no psychoactive effects. Tests have put ACDC\\\\u2019s CBD content as high as 19%, which helps many patients treat pain, anxiety, epilepsy, multiple sclerosis, and the negative effects of chemotherapy, all without intoxication.\",\"1517\":\"Omega Dawg is a 50\\\\/50 hybrid cross between Chemdawg\\\\u00a0and Space Queen. Bred by Alphakronik Genes, this strain inherits a skunky diesel aroma from its Chemdawg mother along with thick trichome coverage courtesy of Space Queen. Balancing full-body relaxation with cerebral euphoria, Omega Dawg is typically chosen by patients treating pain, multiple sclerosis, and muscular dystrophy. Cultivators will harvest flowers between 65 and 75 days indoors or in October for outdoor grows, keeping in mind that Omega Dawg needs plenty of room for root growth and an abundance of nitrogen.\",\"2290\":\"Bred by British Columbia Seed Company, White Lightning is an indica-dominant hybrid that combines White Widow and Northern Lights #5. Though counterbalanced by White Widow\\\\u2019s hybrid genetics, White Lightning induces a deep indica calm that relieves pain, nausea, and anxiety. Dusted in a heavy coat of sugary trichome crystals, White Lightning has a sweet, fruity aroma with floral, skunky undertones. Among the most common conditions treated with White Lightning are multiple sclerosis, insomnia, anorexia, Parkinson\\\\u2019s, and the side effects of chemotherapy. White Lightning flowers in 8 weeks, and grows best in hydroponic systems and sea of green environments.\\\\u00a0\",\"711\":\"A cross between Blue Dream and Stardawg, Dream Star is a sativa-dominant hybrid bred by Oaksterdam Seed Co. Its aroma is sweet and fruity, with sour accents that hint at Dream Star\\\\u2019s Chemdawg lineage. This strain\\\\u2019s psychoactive onset begins in the head and evens out over time into a mellow full-body calm. Dream Star is used by patients to treat a variety of symptoms and conditions including headaches, pain, depression, multiple sclerosis, and Parkinson\\\\u2019s. This hybrid might come as a challenge to novice growers, but cultivators of this strain should wait nine weeks for indoor plants to flower.\",\"1951\":\"The three-time Cannabis Cup winning Sour Power is a sativa-dominant hybrid bred by HortiLab Seeds. A cross between StarBud and East Coast Sour Diesel, Sour Power buds are crowned with pale pointed leaves and a garland of orange hairs. Medical cannabis patients treating anxiety, PTSD, depression, nausea, Crohn\\\\u2019s disease, glaucoma, and inflammation have recommended Sour Power. However, the strain\\\\u2019s typically high THC content should be considered with caution by new consumers, as THC may aggravate anxiety symptoms in some individuals. Sour Power plants thrive indoors, with a flowering time of 9 to 11 weeks and heavy yields.\"},\"symptoms_diseases\":{\"22\":\"multiple sclerosis, epilepsy, pain, \",\"1517\":\"multiple sclerosis, pain, \",\"2290\":\"insomnia, nausea, anorexia, ms, multiple sclerosis, pain, \",\"711\":\"headache, ms, multiple sclerosis, depression, pain, \",\"1951\":\"inflammation, nausea, glaucoma, ms, ptsd, depression, \"},\"score\":{\"22\":1.0,\"1517\":0.9827933473,\"2290\":0.9741748967,\"711\":0.971077099,\"1951\":0.9709200108}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUcmcxY8dwdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPvI5cTNdwbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IpojfeCN2oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cEykY6QMfgyA"
      },
      "source": [
        "# 4 space Effects Version where everything happens in one \"predict\" function\n",
        "## json output effect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "POgxFFtVfgyD",
        "colab": {}
      },
      "source": [
        "\n",
        "# 4 spaced effect json version\n",
        "\n",
        "# user input\n",
        "user_input = \"Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "\n",
        "\n",
        "def predict_effect(user_input):\n",
        "\n",
        "    # getting data\n",
        "    df = pd.read_csv('symptoms6_medcab3.csv')\n",
        "\n",
        "    #effcts unpickling file of embedded cultivar descriptions\n",
        "    unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "    # Part 1\n",
        "    # a function to calculate_user_text_embedding\n",
        "    # to save the embedding value in session memory\n",
        "    user_input_embedding = 0\n",
        "\n",
        "    def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "        # setting a string of two sentences for the algo to compare\n",
        "        sentences = [input]\n",
        "\n",
        "        # calculating embedding for both user_entered_text and for features\n",
        "        with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "            user_input_embedding = list(c.embed_sentences(sentences))\n",
        "        \n",
        "        return user_input_embedding\n",
        "\n",
        "    # run the function to save the embedding value in session memory\n",
        "    user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # part 2\n",
        "    score = 0\n",
        "\n",
        "    def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "        # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "        embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "        \n",
        "        # calculates the similarity of user_text vs. product description\n",
        "        score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "        # returns a variable that can be used outside of the function\n",
        "        return score\n",
        "\n",
        "\n",
        "\n",
        "    # Part 3\n",
        "    for i in range(2351):\n",
        "        # calls the function to set the value of 'score'\n",
        "        # which is the score of the user input\n",
        "        score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "        \n",
        "        #stores the score in the dataframe\n",
        "        df.loc[i,'score'] = score\n",
        "\n",
        "    # Part 4: returns all data for the top 5 results as a json obj\n",
        "    df_big_json = df.sort_values(by='score', ascending=False)\n",
        "    df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "    df_big_json = df_big_json[:5]\n",
        "    df_big_json = df_big_json.to_json(orient='columns')\n",
        "\n",
        "    # Part 5: output\n",
        "    return df_big_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b6532362-9d24-4795-f9dc-eaee1bcd8b95",
        "id": "h8H43m2kfgyG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "predict_effect(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Strain\":{\"1\":\"98-White-Widow\",\"1682\":\"Purple-Diesel\",\"1207\":\"Kush-Cleaner\",\"1163\":\"Kali-Dog\",\"304\":\"Blue-Monster\"},\"Type\":{\"1\":\"hybrid\",\"1682\":\"hybrid\",\"1207\":\"hybrid\",\"1163\":\"hybrid\",\"304\":\"indica\"},\"Rating\":{\"1\":4.7,\"1682\":4.2,\"1207\":4.6,\"1163\":4.8,\"304\":4.7},\"Effects\":{\"1\":\"Relaxed,Aroused,Creative,Happy,Energetic\",\"1682\":\"Relaxed,Uplifted,Happy,Energetic,Focused\",\"1207\":\"Relaxed,Euphoric,Aroused,Creative,Energetic\",\"1163\":\"Relaxed,Uplifted,Happy,Focused,Energetic\",\"304\":\"Relaxed,Hungry,Talkative,Sleepy,Happy\"},\"Flavor\":{\"1\":\"Flowery,Violet,Diesel\",\"1682\":\"Sweet,Berry,Diesel\",\"1207\":\"Woody,Pine,Diesel\",\"1163\":\"Citrus,Lemon,Diesel\",\"304\":\"Berry,Sweet,Diesel\"},\"Description\":{\"1\":\"The \\\\u201898 Aloha White Widow is an especially potent cut of White Widow that has grown in renown alongside Hawaiian legends like Maui Wowie and Kona Gold. This White Widow phenotype reeks of diesel and skunk and has a rich earthy taste with intermittent notes of hash. Its buds are coated in trichomes, giving its dark foliage a lustrous glint to go along with its room-filling odor. This one-hitter-quitter uplifts the mind with mind-bending euphoria that materializes in the body as airy relaxation. \\\\u201898 Aloha White Widow is available from Pua Mana 1st Hawaiian Pakal\\\\u014dl\\\\u014d Seed Bank. \\\\u00a0\",\"1682\":\"Purple Diesel, bred by Cali Connection, is a wonder among hybrid strains. While most of the effects are similar to traditional sativas (energizing, uplifting, focused), Purple D is also an exceptional strain for pain relief. A sneaky cross between Pre-98 Bubba Kush\\\\u00a0and Sour Diesel, this strain takes a while to fully kick in. However, once the effects begin to present themselves, users are struck by a type of giggly, euphoric bliss. A favorite among daytime users, Purple Diesel features a sour, fuel-like aroma. For those interested in growing, this strain has an early flowering time of around 8 weeks and features dense buds with deep purple leaves.\",\"1207\":\"Kush Cleaner is a hybrid strain that combines Kush genetics with Jack\\\\u2019s Cleaner. Exactly which Kush was used in breeding this sativa-leaning strain is up for debate, but OG Kush, Ogre, and Purple Kush are all likely suspects. Its aroma is a strong mix of earthiness and pine, much like that of its Jack Herer ancestor. Expect Kush Cleaner to focus its efforts cerebrally, but its mellow relaxation will eventually permeate throughout the body, easing pain and tension. \\\\u00a0\",\"1163\":\"This OG Kush and Sour Diesel hybrid from Royal Queen Seeds is a powerful strain that has an overwhelming aroma of lemons and diesel fuel. Kali Dog is a sativa-dominant cross but a heavy influence from the indica genetics gives this strain a balanced effect that is described as uplifting, relaxing, and cerebral.\",\"304\":\"Blue Monster is a powerful combination of G13, Blueberry, Northern Lights #5, and a Mexican landrace strain. Bred by Goldenseed, Blue Monster combines a sweet mix of flavors with strong indica effects. Its complex aroma of berries and tropical fruits exposes the influence of Blueberry and G13 genetics. When grown to its full potential, the forceful relaxation of Blue Monster can overwhelm novices with its immediate body sedation and commanding cerebral effects. This monster indica is sure to scare away sleepless nights and body pains.\"},\"symptoms_diseases\":{\"1\":\" \",\"1682\":\"ms, pain, \",\"1207\":\"pain, \",\"1163\":\" \",\"304\":\"pain, \"},\"score\":{\"1\":0.9937762838,\"1682\":0.9808026418,\"1207\":0.9744323931,\"1163\":0.9738405807,\"304\":0.9720477877}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B2cqHbKBfgyK"
      },
      "source": [
        "# 4 spaced Symptom Version where everything happens in one \"predict\" function\n",
        "## json output Symptom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jkRlBfwVfgyL",
        "colab": {}
      },
      "source": [
        "# 4 spaced symptoms json version\n",
        "# user input\n",
        "user_input = \"multiple sclerosis, epilepsy, pain, \"\n",
        "\n",
        "def predict_symptom(user_input):\n",
        "\n",
        "    #unpickling file of embedded cultivar symptoms diseases\n",
        "    unpickled_df_test = pd.read_pickle(\"./symptommedembedv6.pkl\")\n",
        "\n",
        "    # getting data\n",
        "    df = pd.read_csv('symptoms6_medcab3.csv')\n",
        "\n",
        "    # Part 1\n",
        "    # a function to calculate_user_text_embedding\n",
        "    # to save the embedding value in session memory\n",
        "    user_input_embedding = 0\n",
        "\n",
        "    def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "        # setting a string of two sentences for the algo to compare\n",
        "        sentences = [input]\n",
        "\n",
        "        # calculating embedding for both user_entered_text and for features\n",
        "        with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "            user_input_embedding = list(c.embed_sentences(sentences))\n",
        "        \n",
        "        return user_input_embedding\n",
        "\n",
        "    # run the function to save the embedding value in session memory\n",
        "    user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # part 2\n",
        "    score = 0\n",
        "\n",
        "    def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "        # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "        embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "        \n",
        "        # calculates the similarity of user_text vs. product description\n",
        "        score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "        # returns a variable that can be used outside of the function\n",
        "        return score\n",
        "\n",
        "\n",
        "\n",
        "    # Part 3\n",
        "    for i in range(2351):\n",
        "        # calls the function to set the value of 'score'\n",
        "        # which is the score of the user input\n",
        "        score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "        \n",
        "        #stores the score in the dataframe\n",
        "        df.loc[i,'score'] = score\n",
        "\n",
        "\n",
        "    # Part 4: returns all data for the top 5 results as a json obj\n",
        "    df_big_json = df.sort_values(by='score', ascending=False)\n",
        "    df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "    df_big_json = df_big_json[:5]\n",
        "    df_big_json = df_big_json.to_json(orient='columns')\n",
        "\n",
        "    # Part 5: output\n",
        "    return df_big_json\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "394fca65-6275-4d2d-eb27-577bda3c568e",
        "id": "Zr7qvbJ-fgyP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "predict_symptom(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Strain\":{\"22\":\"Acdc\",\"1517\":\"Omega-Dawg\",\"2290\":\"White-Lightning\",\"711\":\"Dream-Star\",\"1951\":\"Sour-Power\"},\"Type\":{\"22\":\"hybrid\",\"1517\":\"hybrid\",\"2290\":\"hybrid\",\"711\":\"hybrid\",\"1951\":\"hybrid\"},\"Rating\":{\"22\":4.5,\"1517\":4.4,\"2290\":4.4,\"711\":4.8,\"1951\":4.7},\"Effects\":{\"22\":\"Relaxed,Happy,Uplifted,Focused,Euphoric\",\"1517\":\"Uplifted,Euphoric,Relaxed,Happy,Tingly\",\"2290\":\"Happy,Giggly,Uplifted,Euphoric,Relaxed\",\"711\":\"Euphoric,Creative,Uplifted,Talkative,Relaxed\",\"1951\":\"Happy,Euphoric,Energetic,Talkative,Hungry\"},\"Flavor\":{\"22\":\"Earthy,Pine,Woody\",\"1517\":\"Diesel,Sweet,Earthy\",\"2290\":\"Sweet,Skunk,Pungent\",\"711\":\"Earthy,Woody,Sweet\",\"1951\":\"Diesel,Skunk,Pungent\"},\"Description\":{\"22\":\"ACDC is\\\\u00a0a sativa-dominant phenotype of the high-CBD\\\\u00a0cannabis strain, Cannatonic. One remarkable characteristic of ACDC is its THC:CBD ratio of 1:20, meaning this strain induces no psychoactive effects. Tests have put ACDC\\\\u2019s CBD content as high as 19%, which helps many patients treat pain, anxiety, epilepsy, multiple sclerosis, and the negative effects of chemotherapy, all without intoxication.\",\"1517\":\"Omega Dawg is a 50\\\\/50 hybrid cross between Chemdawg\\\\u00a0and Space Queen. Bred by Alphakronik Genes, this strain inherits a skunky diesel aroma from its Chemdawg mother along with thick trichome coverage courtesy of Space Queen. Balancing full-body relaxation with cerebral euphoria, Omega Dawg is typically chosen by patients treating pain, multiple sclerosis, and muscular dystrophy. Cultivators will harvest flowers between 65 and 75 days indoors or in October for outdoor grows, keeping in mind that Omega Dawg needs plenty of room for root growth and an abundance of nitrogen.\",\"2290\":\"Bred by British Columbia Seed Company, White Lightning is an indica-dominant hybrid that combines White Widow and Northern Lights #5. Though counterbalanced by White Widow\\\\u2019s hybrid genetics, White Lightning induces a deep indica calm that relieves pain, nausea, and anxiety. Dusted in a heavy coat of sugary trichome crystals, White Lightning has a sweet, fruity aroma with floral, skunky undertones. Among the most common conditions treated with White Lightning are multiple sclerosis, insomnia, anorexia, Parkinson\\\\u2019s, and the side effects of chemotherapy. White Lightning flowers in 8 weeks, and grows best in hydroponic systems and sea of green environments.\\\\u00a0\",\"711\":\"A cross between Blue Dream and Stardawg, Dream Star is a sativa-dominant hybrid bred by Oaksterdam Seed Co. Its aroma is sweet and fruity, with sour accents that hint at Dream Star\\\\u2019s Chemdawg lineage. This strain\\\\u2019s psychoactive onset begins in the head and evens out over time into a mellow full-body calm. Dream Star is used by patients to treat a variety of symptoms and conditions including headaches, pain, depression, multiple sclerosis, and Parkinson\\\\u2019s. This hybrid might come as a challenge to novice growers, but cultivators of this strain should wait nine weeks for indoor plants to flower.\",\"1951\":\"The three-time Cannabis Cup winning Sour Power is a sativa-dominant hybrid bred by HortiLab Seeds. A cross between StarBud and East Coast Sour Diesel, Sour Power buds are crowned with pale pointed leaves and a garland of orange hairs. Medical cannabis patients treating anxiety, PTSD, depression, nausea, Crohn\\\\u2019s disease, glaucoma, and inflammation have recommended Sour Power. However, the strain\\\\u2019s typically high THC content should be considered with caution by new consumers, as THC may aggravate anxiety symptoms in some individuals. Sour Power plants thrive indoors, with a flowering time of 9 to 11 weeks and heavy yields.\"},\"symptoms_diseases\":{\"22\":\"multiple sclerosis, epilepsy, pain, \",\"1517\":\"multiple sclerosis, pain, \",\"2290\":\"insomnia, nausea, anorexia, ms, multiple sclerosis, pain, \",\"711\":\"headache, ms, multiple sclerosis, depression, pain, \",\"1951\":\"inflammation, nausea, glaucoma, ms, ptsd, depression, \"},\"score\":{\"22\":1.0,\"1517\":0.9827933473,\"2290\":0.9741748967,\"711\":0.971077099,\"1951\":0.9709200108}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5G98-EMdwSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H94iC9Y4OxfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gaa7Zt2wOxcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WbqkJfOfbTf",
        "colab_type": "text"
      },
      "source": [
        "# All_Text_Search\n",
        "# 4 space\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFrjGF65PDLc",
        "colab_type": "text"
      },
      "source": [
        "## String"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8bP94AkGN3L5",
        "colab": {}
      },
      "source": [
        "# all text - string\n",
        "# user input\n",
        "user_input = \"pain, Relaxed, Sleepy\"\n",
        "\n",
        "def predict_all(user_input_all):\n",
        "\n",
        "    #unpickling file of embedded cultivar symptoms diseases\n",
        "    unpickled_df_test = pd.read_pickle(\"./all_text_medembedv8.pkl\")\n",
        "\n",
        "    # getting data\n",
        "    df = pd.read_csv('symptoms8_medcab3.csv')\n",
        "\n",
        "    # Part 1\n",
        "    # a function to calculate_user_text_embedding\n",
        "    # to save the embedding value in session memory\n",
        "    user_input_embedding = 0\n",
        "\n",
        "    def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "        # setting a string of two sentences for the algo to compare\n",
        "        sentences = [input]\n",
        "\n",
        "        # calculating embedding for both user_entered_text and for features\n",
        "        with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "            user_input_embedding = list(c.embed_sentences(sentences))\n",
        "        \n",
        "        return user_input_embedding\n",
        "\n",
        "    # run the function to save the embedding value in session memory\n",
        "    user_input_embedding = calculate_user_text_embedding(user_input_all, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "    # part 2\n",
        "    score = 0\n",
        "\n",
        "    def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "        # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "        embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "        \n",
        "        # calculates the similarity of user_text vs. product description\n",
        "        score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "        # returns a variable that can be used outside of the function\n",
        "        return score\n",
        "\n",
        "\n",
        "\n",
        "    # Part 3\n",
        "    for i in range(2351):\n",
        "        # calls the function to set the value of 'score'\n",
        "        # which is the score of the user input\n",
        "        score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "        \n",
        "        #stores the score in the dataframe\n",
        "        df.loc[i,'score'] = score\n",
        "\n",
        "\n",
        "    # Part 4: returns all data for the top 5 results as a json obj\n",
        "    df_big_json = df.sort_values(by='score', ascending=False)\n",
        "    df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "    df_big_json = df_big_json[:5]\n",
        "    #df_big_json = df_big_json.to_json(orient='columns')\n",
        "    string1 = df_big_json['Strain'].values\n",
        "    string1 = str(string1)\n",
        "    string1\n",
        "\n",
        "    # Part 5: output\n",
        "    return string1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "755af746-541f-4cd1-ea39-43c2856545ce",
        "id": "gp5O8TO2N3L9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predict_all(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['Redd-Cross' 'Purple-Pantera' 'Strawberry-Alien-Kush' 'Bronze-Whaler'\\n 'Bubba-Berry']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCicnNM5PGo2",
        "colab_type": "text"
      },
      "source": [
        "##Json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2_6G41YOxan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4 spaced all_text json version\n",
        "# user input\n",
        "user_input = \"multiple sclerosis, epilepsy, pain, \"\n",
        "\n",
        "def predict_all(user_input_all):\n",
        "\n",
        "    #unpickling file of embedded cultivar symptoms diseases\n",
        "    unpickled_df_test = pd.read_pickle(\"./all_text_medembedv8.pkl\")\n",
        "\n",
        "    # getting data\n",
        "    df = pd.read_csv('symptoms8_medcab3.csv')\n",
        "\n",
        "    # Part 1\n",
        "    # a function to calculate_user_text_embedding\n",
        "    # to save the embedding value in session memory\n",
        "    user_input_embedding = 0\n",
        "\n",
        "    def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "        # setting a string of two sentences for the algo to compare\n",
        "        sentences = [input]\n",
        "\n",
        "        # calculating embedding for both user_entered_text and for features\n",
        "        with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "            user_input_embedding = list(c.embed_sentences(sentences))\n",
        "        \n",
        "        return user_input_embedding\n",
        "\n",
        "    # run the function to save the embedding value in session memory\n",
        "    user_input_embedding = calculate_user_text_embedding(user_input_all, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # part 2\n",
        "    score = 0\n",
        "\n",
        "    def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "        # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "        embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "        \n",
        "        # calculates the similarity of user_text vs. product description\n",
        "        score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "        # returns a variable that can be used outside of the function\n",
        "        return score\n",
        "\n",
        "\n",
        "\n",
        "    # Part 3\n",
        "    for i in range(2351):\n",
        "        # calls the function to set the value of 'score'\n",
        "        # which is the score of the user input\n",
        "        score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "        \n",
        "        #stores the score in the dataframe\n",
        "        df.loc[i,'score'] = score\n",
        "\n",
        "\n",
        "    # Part 4: returns all data for the top 5 results as a json obj\n",
        "    df_big_json = df.sort_values(by='score', ascending=False)\n",
        "    df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "    df_big_json = df_big_json[:5]\n",
        "    df_big_json = df_big_json.to_json(orient='columns')\n",
        "\n",
        "    # Part 5: output\n",
        "    return df_big_json\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94zaO-L3OxX8",
        "colab_type": "code",
        "outputId": "23766bb0-7c27-42d0-b89f-cb63bc4bbfc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "predict_all(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Strain\":{\"1951\":\"Sour-Power\",\"607\":\"Critical-Plus\",\"571\":\"Commerce-City-Kush\",\"2290\":\"White-Lightning\",\"2241\":\"Wmd\"},\"Type\":{\"1951\":\"hybrid\",\"607\":\"hybrid\",\"571\":\"indica\",\"2290\":\"hybrid\",\"2241\":\"indica\"},\"Rating\":{\"1951\":4.7,\"607\":4.2,\"571\":4.3,\"2290\":4.4,\"2241\":4.9},\"Effects\":{\"1951\":\"Happy, Euphoric, Energetic, Talkative, Hungry\",\"607\":\"Relaxed, Happy, Hungry, Sleepy, Creative\",\"571\":\"Relaxed, Sleepy, Euphoric, Happy, Talkative\",\"2290\":\"Happy, Giggly, Uplifted, Euphoric, Relaxed\",\"2241\":\"Relaxed, Happy, Euphoric, Tingly, Hungry\"},\"Flavor\":{\"1951\":\"Diesel, Skunk, Pungent\",\"607\":\"Woody, Spicy\\\\/Herbal, Pungent\",\"571\":\"Diesel, Sweet, Flowery\",\"2290\":\"Sweet, Skunk, Pungent\",\"2241\":\"Earthy, Berry, Pungent\"},\"Description\":{\"1951\":\"The three-time Cannabis Cup winning Sour Power is a sativa-dominant hybrid bred by HortiLab Seeds. A cross between StarBud and East Coast Sour Diesel, Sour Power buds are crowned with pale pointed leaves and a garland of orange hairs. Medical cannabis patients treating anxiety, PTSD, depression, nausea, Crohn\\\\u2019s disease, glaucoma, and inflammation have recommended Sour Power. However, the strain\\\\u2019s typically high THC content should be considered with caution by new consumers, as THC may aggravate anxiety symptoms in some individuals. Sour Power plants thrive indoors, with a flowering time of 9 to 11 weeks and heavy yields.\",\"607\":\"Critical Plus (or Critical +) is a cross of Skunk and Big Bud that won the first Highlife Cup in Barcelona and has gone on to find a small but loyal following in regions of the USA, particularly the PNW and Desert SW. This fast growing strain produces huge yields of dense, extremely resinous flowers with an intense aroma of skunk and citrus. Featuring a delicious lemon-lime flavor, Critical Plus is a great mood enhancer, giving users a pleasant, creative head high along with a deeply relaxing body buzz. This strain may be potentially useful in treating depression, anxiety, PTSD, fibromyalgia, and migraines.\",\"571\":\"Commerce City Kush by Rare Dankness is a pungent indica-dominant strain with intense effects. Created by crossing Chemdawg 4 and Rare Dankness #1, this strain delivers fuel-forward aromas and strong physical effects. It hits right between the eyes and lingers, offering a strong cerebral buzz that sinks into the body. Enjoy Commerce City Kush in the early evening or in a place you intend to stay, as the mental and physical effects can be arresting. The breeder recommends utilizing this strain for GI issues, depression, migraines, and nausea.\\\\u00a0\",\"2290\":\"Bred by British Columbia Seed Company, White Lightning is an indica-dominant hybrid that combines White Widow and Northern Lights #5. Though counterbalanced by White Widow\\\\u2019s hybrid genetics, White Lightning induces a deep indica calm that relieves pain, nausea, and anxiety. Dusted in a heavy coat of sugary trichome crystals, White Lightning has a sweet, fruity aroma with floral, skunky undertones. Among the most common conditions treated with White Lightning are multiple sclerosis, insomnia, anorexia, Parkinson\\\\u2019s, and the side effects of chemotherapy. White Lightning flowers in 8 weeks, and grows best in hydroponic systems and sea of green environments.\\\\u00a0\",\"2241\":\"WMD by Vancouver Island Seed Company is a high-yielding indica with potent Canadian roots. It exhibits a unique aroma of sweet berry, musk, and hashy spice that remains earthy on the palate after exhaling. The effects are initially cerebral, but they later settle down into the body to relax and soothe limbs. This cross of Big Bud and Fucking Incredible may offer relief from depression, minor physical pain, and migraines\"},\"symptoms_diseases\":{\"1951\":\"inflammation, anxiety, nausea, glaucoma, ms, ptsd, depression, \",\"607\":\"migraines, anxiety, ptsd, depression, \",\"571\":\"migraines, nausea, depression, \",\"2290\":\"insomnia, anxiety, nausea, anorexia, ms, multiple sclerosis, pain, \",\"2241\":\"migraines, depression, pain, \"},\"all_text_search\":{\"1951\":\"inflammation, anxiety, nausea, glaucoma, ms, ptsd, depression, Happy, Euphoric, Energetic, Talkative, Hungry, Diesel, Skunk, Pungent\",\"607\":\"migraines, anxiety, ptsd, depression, Relaxed, Happy, Hungry, Sleepy, Creative, Woody, Spicy\\\\/Herbal, Pungent\",\"571\":\"migraines, nausea, depression, Relaxed, Sleepy, Euphoric, Happy, Talkative, Diesel, Sweet, Flowery\",\"2290\":\"insomnia, anxiety, nausea, anorexia, ms, multiple sclerosis, pain, Happy, Giggly, Uplifted, Euphoric, Relaxed, Sweet, Skunk, Pungent\",\"2241\":\"migraines, depression, pain, Relaxed, Happy, Euphoric, Tingly, Hungry, Earthy, Berry, Pungent\"},\"score\":{\"1951\":0.8977477847,\"607\":0.8872207396,\"571\":0.8756997249,\"2290\":0.8749297933,\"2241\":0.8737973183}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P889l5fvOxVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upYjSckiOxTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrrGUt4BOxQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7wrq-G5ZaiH",
        "colab_type": "text"
      },
      "source": [
        "# Json output code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOZWq8N4Zchb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcEUW4DBGklq",
        "colab_type": "text"
      },
      "source": [
        "# after here sandbox for experimenting with better form of output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKy19dQ5Gj89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DBzhtLcBGrXd",
        "colab": {}
      },
      "source": [
        "# user input\n",
        "user_input = \"multiple sclerosis, epilepsy, pain, \"\n",
        "\n",
        "#unpickling file of embedded cultivar symptoms diseases\n",
        "unpickled_df_test = pd.read_pickle(\"./symptommedembedv6.pkl\")\n",
        "\n",
        "def predict_symptom(user_input):\n",
        "\n",
        "  \n",
        "\n",
        "  #unpickling file of embedded cultivar symptoms diseases\n",
        "  unpickled_df_test = pd.read_pickle(\"./symptommedembedv6.pkl\")\n",
        "\n",
        "  # Part 1\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that candf_big_json be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "\n",
        "  # Part 4: returns all data for the top 5 results as a json obj\n",
        "  df_big_json = df.sort_values(by='score', ascending=False)\n",
        "  df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "  df_big_json = df_big_json[:5]\n",
        "  df_big_json = df_big_json.to_json(orient='columns')\n",
        "\n",
        "  # Part 5: output\n",
        "  return df_big_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4e6c984b-4c74-47b2-a4af-696e94f4c137",
        "id": "XWg-1-k7GrXl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "predict_symptom(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Strain\":{\"22\":\"Acdc\",\"1517\":\"Omega-Dawg\",\"2290\":\"White-Lightning\",\"711\":\"Dream-Star\",\"1951\":\"Sour-Power\"},\"Type\":{\"22\":\"hybrid\",\"1517\":\"hybrid\",\"2290\":\"hybrid\",\"711\":\"hybrid\",\"1951\":\"hybrid\"},\"Rating\":{\"22\":4.5,\"1517\":4.4,\"2290\":4.4,\"711\":4.8,\"1951\":4.7},\"Effects\":{\"22\":\"Relaxed,Happy,Uplifted,Focused,Euphoric\",\"1517\":\"Uplifted,Euphoric,Relaxed,Happy,Tingly\",\"2290\":\"Happy,Giggly,Uplifted,Euphoric,Relaxed\",\"711\":\"Euphoric,Creative,Uplifted,Talkative,Relaxed\",\"1951\":\"Happy,Euphoric,Energetic,Talkative,Hungry\"},\"Flavor\":{\"22\":\"Earthy,Pine,Woody\",\"1517\":\"Diesel,Sweet,Earthy\",\"2290\":\"Sweet,Skunk,Pungent\",\"711\":\"Earthy,Woody,Sweet\",\"1951\":\"Diesel,Skunk,Pungent\"},\"Description\":{\"22\":\"ACDC is\\\\u00a0a sativa-dominant phenotype of the high-CBD\\\\u00a0cannabis strain, Cannatonic. One remarkable characteristic of ACDC is its THC:CBD ratio of 1:20, meaning this strain induces no psychoactive effects. Tests have put ACDC\\\\u2019s CBD content as high as 19%, which helps many patients treat pain, anxiety, epilepsy, multiple sclerosis, and the negative effects of chemotherapy, all without intoxication.\",\"1517\":\"Omega Dawg is a 50\\\\/50 hybrid cross between Chemdawg\\\\u00a0and Space Queen. Bred by Alphakronik Genes, this strain inherits a skunky diesel aroma from its Chemdawg mother along with thick trichome coverage courtesy of Space Queen. Balancing full-body relaxation with cerebral euphoria, Omega Dawg is typically chosen by patients treating pain, multiple sclerosis, and muscular dystrophy. Cultivators will harvest flowers between 65 and 75 days indoors or in October for outdoor grows, keeping in mind that Omega Dawg needs plenty of room for root growth and an abundance of nitrogen.\",\"2290\":\"Bred by British Columbia Seed Company, White Lightning is an indica-dominant hybrid that combines White Widow and Northern Lights #5. Though counterbalanced by White Widow\\\\u2019s hybrid genetics, White Lightning induces a deep indica calm that relieves pain, nausea, and anxiety. Dusted in a heavy coat of sugary trichome crystals, White Lightning has a sweet, fruity aroma with floral, skunky undertones. Among the most common conditions treated with White Lightning are multiple sclerosis, insomnia, anorexia, Parkinson\\\\u2019s, and the side effects of chemotherapy. White Lightning flowers in 8 weeks, and grows best in hydroponic systems and sea of green environments.\\\\u00a0\",\"711\":\"A cross between Blue Dream and Stardawg, Dream Star is a sativa-dominant hybrid bred by Oaksterdam Seed Co. Its aroma is sweet and fruity, with sour accents that hint at Dream Star\\\\u2019s Chemdawg lineage. This strain\\\\u2019s psychoactive onset begins in the head and evens out over time into a mellow full-body calm. Dream Star is used by patients to treat a variety of symptoms and conditions including headaches, pain, depression, multiple sclerosis, and Parkinson\\\\u2019s. This hybrid might come as a challenge to novice growers, but cultivators of this strain should wait nine weeks for indoor plants to flower.\",\"1951\":\"The three-time Cannabis Cup winning Sour Power is a sativa-dominant hybrid bred by HortiLab Seeds. A cross between StarBud and East Coast Sour Diesel, Sour Power buds are crowned with pale pointed leaves and a garland of orange hairs. Medical cannabis patients treating anxiety, PTSD, depression, nausea, Crohn\\\\u2019s disease, glaucoma, and inflammation have recommended Sour Power. However, the strain\\\\u2019s typically high THC content should be considered with caution by new consumers, as THC may aggravate anxiety symptoms in some individuals. Sour Power plants thrive indoors, with a flowering time of 9 to 11 weeks and heavy yields.\"},\"symptoms_diseases\":{\"22\":\"multiple sclerosis, epilepsy, pain, \",\"1517\":\"multiple sclerosis, pain, \",\"2290\":\"insomnia, nausea, anorexia, ms, multiple sclerosis, pain, \",\"711\":\"headache, ms, multiple sclerosis, depression, pain, \",\"1951\":\"inflammation, nausea, glaucoma, ms, ptsd, depression, \"},\"score\":{\"22\":1.0,\"1517\":0.9827933473,\"2290\":0.9741748967,\"711\":0.971077099,\"1951\":0.9709200108}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3ZSuES_QJBS",
        "colab_type": "text"
      },
      "source": [
        "## inspection outside of function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEXJp1mgGj6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1LKOSt8tQN5t",
        "outputId": "631eb910-a52a-4f41-ca9f-dc11203947bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# user input\n",
        "user_input = \"multiple sclerosis, epilepsy, pain, \"\n",
        "\n",
        "\n",
        "# Part 1\n",
        "# a function to calculate_user_text_embedding\n",
        "# to save the embedding value in session memory\n",
        "user_input_embedding = 0\n",
        "\n",
        "def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "  # setting a string of two sentences for the algo to compare\n",
        "  sentences = [input]\n",
        "\n",
        "  # calculating embedding for both user_entered_text and for features\n",
        "  with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "    user_input_embedding = list(c.embed_sentences(sentences))\n",
        "  \n",
        "  return user_input_embedding\n",
        "\n",
        "# run the function to save the embedding value in session memory\n",
        "user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# part 2\n",
        "score = 0\n",
        "\n",
        "def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "  # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "  embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "  \n",
        "  # calculates the similarity of user_text vs. product description\n",
        "  score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "  # returns a variable that candf_big_json be used outside of the function\n",
        "  return score\n",
        "\n",
        "\n",
        "\n",
        "# Part 3\n",
        "for i in range(2351):\n",
        "  # calls the function to set the value of 'score'\n",
        "  # which is the score of the user input\n",
        "  score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "  \n",
        "  #stores the score in the dataframe\n",
        "  df.loc[i,'score'] = score\n",
        "\n",
        "\n",
        "# Part 4: returns all data for the top 5 results as a json obj\n",
        "df_big_json = df.sort_values(by='score', ascending=False)\n",
        "df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "df_big_json = df_big_json[:5]\n",
        "df_big_json = df_big_json.to_json(orient='columns')\n",
        "\n",
        "# Part 5: output\n",
        "#return df_big_json\n",
        "df_big_json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Strain\":{\"22\":\"Acdc\",\"1517\":\"Omega-Dawg\",\"2290\":\"White-Lightning\",\"711\":\"Dream-Star\",\"1951\":\"Sour-Power\"},\"Type\":{\"22\":\"hybrid\",\"1517\":\"hybrid\",\"2290\":\"hybrid\",\"711\":\"hybrid\",\"1951\":\"hybrid\"},\"Rating\":{\"22\":4.5,\"1517\":4.4,\"2290\":4.4,\"711\":4.8,\"1951\":4.7},\"Effects\":{\"22\":\"Relaxed,Happy,Uplifted,Focused,Euphoric\",\"1517\":\"Uplifted,Euphoric,Relaxed,Happy,Tingly\",\"2290\":\"Happy,Giggly,Uplifted,Euphoric,Relaxed\",\"711\":\"Euphoric,Creative,Uplifted,Talkative,Relaxed\",\"1951\":\"Happy,Euphoric,Energetic,Talkative,Hungry\"},\"Flavor\":{\"22\":\"Earthy,Pine,Woody\",\"1517\":\"Diesel,Sweet,Earthy\",\"2290\":\"Sweet,Skunk,Pungent\",\"711\":\"Earthy,Woody,Sweet\",\"1951\":\"Diesel,Skunk,Pungent\"},\"Description\":{\"22\":\"ACDC is\\\\u00a0a sativa-dominant phenotype of the high-CBD\\\\u00a0cannabis strain, Cannatonic. One remarkable characteristic of ACDC is its THC:CBD ratio of 1:20, meaning this strain induces no psychoactive effects. Tests have put ACDC\\\\u2019s CBD content as high as 19%, which helps many patients treat pain, anxiety, epilepsy, multiple sclerosis, and the negative effects of chemotherapy, all without intoxication.\",\"1517\":\"Omega Dawg is a 50\\\\/50 hybrid cross between Chemdawg\\\\u00a0and Space Queen. Bred by Alphakronik Genes, this strain inherits a skunky diesel aroma from its Chemdawg mother along with thick trichome coverage courtesy of Space Queen. Balancing full-body relaxation with cerebral euphoria, Omega Dawg is typically chosen by patients treating pain, multiple sclerosis, and muscular dystrophy. Cultivators will harvest flowers between 65 and 75 days indoors or in October for outdoor grows, keeping in mind that Omega Dawg needs plenty of room for root growth and an abundance of nitrogen.\",\"2290\":\"Bred by British Columbia Seed Company, White Lightning is an indica-dominant hybrid that combines White Widow and Northern Lights #5. Though counterbalanced by White Widow\\\\u2019s hybrid genetics, White Lightning induces a deep indica calm that relieves pain, nausea, and anxiety. Dusted in a heavy coat of sugary trichome crystals, White Lightning has a sweet, fruity aroma with floral, skunky undertones. Among the most common conditions treated with White Lightning are multiple sclerosis, insomnia, anorexia, Parkinson\\\\u2019s, and the side effects of chemotherapy. White Lightning flowers in 8 weeks, and grows best in hydroponic systems and sea of green environments.\\\\u00a0\",\"711\":\"A cross between Blue Dream and Stardawg, Dream Star is a sativa-dominant hybrid bred by Oaksterdam Seed Co. Its aroma is sweet and fruity, with sour accents that hint at Dream Star\\\\u2019s Chemdawg lineage. This strain\\\\u2019s psychoactive onset begins in the head and evens out over time into a mellow full-body calm. Dream Star is used by patients to treat a variety of symptoms and conditions including headaches, pain, depression, multiple sclerosis, and Parkinson\\\\u2019s. This hybrid might come as a challenge to novice growers, but cultivators of this strain should wait nine weeks for indoor plants to flower.\",\"1951\":\"The three-time Cannabis Cup winning Sour Power is a sativa-dominant hybrid bred by HortiLab Seeds. A cross between StarBud and East Coast Sour Diesel, Sour Power buds are crowned with pale pointed leaves and a garland of orange hairs. Medical cannabis patients treating anxiety, PTSD, depression, nausea, Crohn\\\\u2019s disease, glaucoma, and inflammation have recommended Sour Power. However, the strain\\\\u2019s typically high THC content should be considered with caution by new consumers, as THC may aggravate anxiety symptoms in some individuals. Sour Power plants thrive indoors, with a flowering time of 9 to 11 weeks and heavy yields.\"},\"symptoms_diseases\":{\"22\":\"multiple sclerosis, epilepsy, pain, \",\"1517\":\"multiple sclerosis, pain, \",\"2290\":\"insomnia, nausea, anorexia, ms, multiple sclerosis, pain, \",\"711\":\"headache, ms, multiple sclerosis, depression, pain, \",\"1951\":\"inflammation, nausea, glaucoma, ms, ptsd, depression, \"},\"score\":{\"22\":1.0,\"1517\":0.9827933473,\"2290\":0.9741748967,\"711\":0.971077099,\"1951\":0.9709200108}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LehRuUntUYCB",
        "colab_type": "code",
        "outputId": "34b90590-9d7b-4ddd-9947-471001313115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "# user input\n",
        "user_input = \"multiple sclerosis, epilepsy, pain, \"\n",
        "\n",
        "\n",
        "# Part 1\n",
        "# a function to calculate_user_text_embedding\n",
        "# to save the embedding value in session memory\n",
        "user_input_embedding = 0\n",
        "\n",
        "def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "  # setting a string of two sentences for the algo to compare\n",
        "  sentences = [input]\n",
        "\n",
        "  # calculating embedding for both user_entered_text and for features\n",
        "  with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "    user_input_embedding = list(c.embed_sentences(sentences))\n",
        "  \n",
        "  return user_input_embedding\n",
        "\n",
        "# run the function to save the embedding value in session memory\n",
        "user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# part 2\n",
        "score = 0\n",
        "\n",
        "def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "  # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "  embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "  \n",
        "  # calculates the similarity of user_text vs. product description\n",
        "  score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "  # returns a variable that candf_big_json be used outside of the function\n",
        "  return score\n",
        "\n",
        "\n",
        "\n",
        "# Part 3\n",
        "for i in range(2351):\n",
        "  # calls the function to set the value of 'score'\n",
        "  # which is the score of the user input\n",
        "  score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "  \n",
        "  #stores the score in the dataframe\n",
        "  df.loc[i,'score'] = score\n",
        "\n",
        "\n",
        "# Part 4: returns all data for the top 5 results as a json obj\n",
        "df_big_json = df.sort_values(by='score', ascending=False)\n",
        "df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "df_big_json = df_big_json[:5]\n",
        "df_big_json\n",
        "#df_big_json = df_big_json.to_json(orient='columns')\n",
        "\n",
        "# Part 5: output\n",
        "#return df_big_json\n",
        "#df_big_json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Strain</th>\n",
              "      <th>Type</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Effects</th>\n",
              "      <th>Flavor</th>\n",
              "      <th>Description</th>\n",
              "      <th>symptoms_diseases</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Acdc</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.5</td>\n",
              "      <td>Relaxed,Happy,Uplifted,Focused,Euphoric</td>\n",
              "      <td>Earthy,Pine,Woody</td>\n",
              "      <td>ACDC is a sativa-dominant phenotype of the hig...</td>\n",
              "      <td>multiple sclerosis, epilepsy, pain,</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>Omega-Dawg</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.4</td>\n",
              "      <td>Uplifted,Euphoric,Relaxed,Happy,Tingly</td>\n",
              "      <td>Diesel,Sweet,Earthy</td>\n",
              "      <td>Omega Dawg is a 50/50 hybrid cross between Che...</td>\n",
              "      <td>multiple sclerosis, pain,</td>\n",
              "      <td>0.982793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2290</th>\n",
              "      <td>White-Lightning</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.4</td>\n",
              "      <td>Happy,Giggly,Uplifted,Euphoric,Relaxed</td>\n",
              "      <td>Sweet,Skunk,Pungent</td>\n",
              "      <td>Bred by British Columbia Seed Company, White L...</td>\n",
              "      <td>insomnia, nausea, anorexia, ms, multiple scler...</td>\n",
              "      <td>0.974175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>Dream-Star</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.8</td>\n",
              "      <td>Euphoric,Creative,Uplifted,Talkative,Relaxed</td>\n",
              "      <td>Earthy,Woody,Sweet</td>\n",
              "      <td>A cross between Blue Dream and Stardawg, Dream...</td>\n",
              "      <td>headache, ms, multiple sclerosis, depression, ...</td>\n",
              "      <td>0.971077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1951</th>\n",
              "      <td>Sour-Power</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.7</td>\n",
              "      <td>Happy,Euphoric,Energetic,Talkative,Hungry</td>\n",
              "      <td>Diesel,Skunk,Pungent</td>\n",
              "      <td>The three-time Cannabis Cup winning Sour Power...</td>\n",
              "      <td>inflammation, nausea, glaucoma, ms, ptsd, depr...</td>\n",
              "      <td>0.970920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Strain  ...     score\n",
              "22               Acdc  ...  1.000000\n",
              "1517       Omega-Dawg  ...  0.982793\n",
              "2290  White-Lightning  ...  0.974175\n",
              "711        Dream-Star  ...  0.971077\n",
              "1951       Sour-Power  ...  0.970920\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Fo5aSVWfkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqpZC__MXBkx",
        "colab_type": "text"
      },
      "source": [
        "# Works as string ouput"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPmk89ipWfiH",
        "colab_type": "code",
        "outputId": "816f9a10-ee86-4cdb-f136-4d456f688934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# symptom, text ouput\n",
        "\n",
        "# user input\n",
        "user_input = \"multiple sclerosis, epilepsy, pain, \"\n",
        "\n",
        "\n",
        "# Part 1\n",
        "# a function to calculate_user_text_embedding\n",
        "# to save the embedding value in session memory\n",
        "user_input_embedding = 0\n",
        "\n",
        "def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "  # setting a string of two sentences for the algo to compare\n",
        "  sentences = [input]\n",
        "\n",
        "  # calculating embedding for both user_entered_text and for features\n",
        "  with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "    user_input_embedding = list(c.embed_sentences(sentences))\n",
        "  \n",
        "  return user_input_embedding\n",
        "\n",
        "# run the function to save the embedding value in session memory\n",
        "user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# part 2\n",
        "score = 0\n",
        "\n",
        "def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "  # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "  embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "  \n",
        "  # calculates the similarity of user_text vs. product description\n",
        "  score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "  # returns a variable that candf_big_json be used outside of the function\n",
        "  return score\n",
        "\n",
        "\n",
        "\n",
        "# Part 3\n",
        "for i in range(2351):\n",
        "  # calls the function to set the value of 'score'\n",
        "  # which is the score of the user input\n",
        "  score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "  \n",
        "  #stores the score in the dataframe\n",
        "  df.loc[i,'score'] = score\n",
        "\n",
        "\n",
        "# Part 4: returns all data for the top 5 results as a json obj\n",
        "df_big_json = df.sort_values(by='score', ascending=False)\n",
        "df_big_json = df_big_json.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
        "df_big_json = df_big_json[:5]\n",
        "#df_big_json = df_big_json.to_json(orient='columns')\n",
        "string1 = df_big_json['Strain'].values\n",
        "string1 = str(string1)\n",
        "string1\n",
        "\n",
        "# Part 5: output\n",
        "return string1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['Acdc' 'Omega-Dawg' 'White-Lightning' 'Dream-Star' 'Sour-Power']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64jmrwyzWfgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # Part 4\n",
        "  output = df['Strain'].groupby(df['score']).value_counts().nlargest(5, keep='last')\n",
        "  output_string = str(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLf4CbMQWfcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tb-epEPWfX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "unm2UhkrQN5y",
        "colab": {}
      },
      "source": [
        "predict_symptom(user_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJVj5w5fGj4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# top five values\n",
        "# send out df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5YYee6rKyNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# symptom sandbox\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98OgAWKqGj22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(user_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOzPT82qGj0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8Ebd4H6Gjxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffqJxmmxW8cP",
        "colab_type": "text"
      },
      "source": [
        "# Super-inclusive function version\n",
        "## raw useless form of ouput (e.g. eronious first item etc)\n",
        "3 cells, two steps\n",
        "1. user_input = \"user med description\"\n",
        "2. predict(user_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J2xSevYXUcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# user input\n",
        "user_input = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb_helY8W8jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(user_input):\n",
        "\n",
        "  # install basilica\n",
        "  !pip install basilica\n",
        "\n",
        "  import basilica\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from scipy import spatial\n",
        "\n",
        "  # get data\n",
        "  !wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
        "  # turn data into dataframe\n",
        "  df = pd.read_csv('med1.csv')\n",
        "\n",
        "  # get pickled trained embeddings for med cultivars\n",
        "  !wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
        "  #unpickling file of embedded cultivar descriptions\n",
        "  unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Part 1\n",
        "  # maybe make a function to perform the last few steps\n",
        "\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "  # Part 4\n",
        "  output = df['Strain'].groupby(df['score']).value_counts().nlargest(5, keep='last')\n",
        "  output_string = str(output)\n",
        "\n",
        "  # Part 5: output\n",
        "  return output_string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK5IE-RwYAEA",
        "colab_type": "code",
        "outputId": "a405cc30-c10b-4c72-d7e2-e70273838081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "predict(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: basilica in /usr/local/lib/python3.6/dist-packages (0.2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from basilica) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from basilica) (2.21.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from basilica) (4.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (3.0.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->basilica) (0.46)\n",
            "--2020-01-07 23:00:32--  https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1267451 (1.2M) [text/plain]\n",
            "Saving to: ‘med1.csv.1’\n",
            "\n",
            "med1.csv.1          100%[===================>]   1.21M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-01-07 23:00:32 (15.9 MB/s) - ‘med1.csv.1’ saved [1267451/1267451]\n",
            "\n",
            "--2020-01-07 23:00:33--  https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/lineality/4.4_Build_files/master/medembedv2.pkl [following]\n",
            "--2020-01-07 23:00:33--  https://raw.githubusercontent.com/lineality/4.4_Build_files/master/medembedv2.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16288303 (16M) [application/octet-stream]\n",
            "Saving to: ‘medembedv2.pkl.1’\n",
            "\n",
            "medembedv2.pkl.1    100%[===================>]  15.53M  86.7MB/s    in 0.2s    \n",
            "\n",
            "2020-01-07 23:00:33 (86.7 MB/s) - ‘medembedv2.pkl.1’ saved [16288303/16288303]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'score     Strain        \\n0.905756  B-Witched         2\\n0.983573  98-White-Widow    1\\n0.969837  Purple-Diesel     1\\n0.964103  Blue-Monster      1\\n0.962950  Deadhead-Og       1\\nName: Strain, dtype: int64'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij5tQ2gdZ81C",
        "colab_type": "text"
      },
      "source": [
        "# one-cell version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IICKdEJZ8Ls",
        "colab_type": "code",
        "outputId": "6a4f7cb3-73bf-44ee-e022-4f0434c686b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "# user input\n",
        "user_input = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "# ominbus function\n",
        "def predict(user_input):\n",
        "\n",
        "  # install basilica\n",
        "  !pip install basilica\n",
        "\n",
        "  import basilica\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from scipy import spatial\n",
        "\n",
        "  # get data\n",
        "  !wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
        "  # turn data into dataframe\n",
        "  df = pd.read_csv('med1.csv')\n",
        "\n",
        "  # get pickled trained embeddings for med cultivars\n",
        "  !wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
        "  #unpickling file of embedded cultivar descriptions\n",
        "  unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Part 1\n",
        "  # maybe make a function to perform the last few steps\n",
        "\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "  # Part 4\n",
        "  output = df['Strain'].groupby(df['score']).value_counts().nlargest(5, keep='last')\n",
        "  output_string = str(output)\n",
        "\n",
        "  # Part 5: output\n",
        "  return output_string\n",
        "\n",
        "predict(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: basilica in /usr/local/lib/python3.6/dist-packages (0.2.8)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from basilica) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from basilica) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from basilica) (2.21.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->basilica) (0.46)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->basilica) (3.0.4)\n",
            "--2020-01-07 23:00:38--  https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1267451 (1.2M) [text/plain]\n",
            "Saving to: ‘med1.csv.2’\n",
            "\n",
            "med1.csv.2          100%[===================>]   1.21M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-01-07 23:00:39 (11.2 MB/s) - ‘med1.csv.2’ saved [1267451/1267451]\n",
            "\n",
            "--2020-01-07 23:00:39--  https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/lineality/4.4_Build_files/master/medembedv2.pkl [following]\n",
            "--2020-01-07 23:00:39--  https://raw.githubusercontent.com/lineality/4.4_Build_files/master/medembedv2.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16288303 (16M) [application/octet-stream]\n",
            "Saving to: ‘medembedv2.pkl.2’\n",
            "\n",
            "medembedv2.pkl.2    100%[===================>]  15.53M  24.0MB/s    in 0.6s    \n",
            "\n",
            "2020-01-07 23:00:40 (24.0 MB/s) - ‘medembedv2.pkl.2’ saved [16288303/16288303]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'score     Strain        \\n0.905756  B-Witched         2\\n0.983573  98-White-Widow    1\\n0.969837  Purple-Diesel     1\\n0.964103  Blue-Monster      1\\n0.962950  Deadhead-Og       1\\nName: Strain, dtype: int64'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaC6ZqSeBZMC",
        "colab_type": "code",
        "outputId": "d5d1627f-feef-4da9-f457-64bb99c67c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# user input\n",
        "user_input = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "# ominbus function\n",
        "def predict(user_input):\n",
        "\n",
        "  # install basilica\n",
        "  #!pip install basilica\n",
        "\n",
        "  import basilica\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from scipy import spatial\n",
        "\n",
        "  # get data\n",
        "  #!wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
        "  # turn data into dataframe\n",
        "  df = pd.read_csv('med1.csv')\n",
        "\n",
        "  # get pickled trained embeddings for med cultivars\n",
        "  #!wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
        "  #unpickling file of embedded cultivar descriptions\n",
        "  unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Part 1\n",
        "  # maybe make a function to perform the last few steps\n",
        "\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "  # Part 4\n",
        "  output = df['Strain'].groupby(df['score']).value_counts().nlargest(5, keep='last')\n",
        "  #print(output)\n",
        "  #print(output[1:])\n",
        "  output_string = str(output)\n",
        "  #print(type(output))\n",
        "  #print(output.shape)\n",
        "  #print(output_string)\n",
        "  import re\n",
        "  output_regex = re.sub(r'[^a-zA-Z ]', '', output_string)\n",
        "  print(output_regex)\n",
        "  output_string_clipped = output_regex[26:-27]\n",
        "  print(output_string_clipped)\n",
        "  # Part 5: output\n",
        "  return output_string_clipped\n",
        "\n",
        "predict(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score     Strain          BWitched           WhiteWidow      PurpleDiesel       BlueMonster        DeadheadOg       Name Strain dtype int\n",
            "BWitched           WhiteWidow      PurpleDiesel       BlueMonster        DeadheadOg \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BWitched           WhiteWidow      PurpleDiesel       BlueMonster        DeadheadOg '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMm9zkA5FpAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this next version fixes the incorrect first listed prediction (why was it showing that?)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytoKcGFxOR4n",
        "colab_type": "code",
        "outputId": "b559bef2-b5d8-49c9-a2c6-de8b24622590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# user input\n",
        "user_input = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "# ominbus function\n",
        "def predict(user_input):\n",
        "\n",
        "  # install basilica\n",
        "  #!pip install basilica\n",
        "\n",
        "  import basilica\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from scipy import spatial\n",
        "\n",
        "  # get data\n",
        "  #!wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
        "  # turn data into dataframe\n",
        "  df = pd.read_csv('med1.csv')\n",
        "\n",
        "  # get pickled trained embeddings for med cultivars\n",
        "  #!wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
        "  #unpickling file of embedded cultivar descriptions\n",
        "  unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Part 1\n",
        "  # maybe make a function to perform the last few steps\n",
        "\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "\n",
        "  # Part 4\n",
        "  output = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "  #print(output)\n",
        "  output_string = str(output)\n",
        "  #print(output_string)\n",
        "  import re\n",
        "  output_regex = re.sub(r'[^a-zA-Z ]', '', output_string)\n",
        "  output_string_clipped = output_regex[39:-28]\n",
        "\n",
        "\n",
        "  # Part 5: output\n",
        "  return output_string_clipped\n",
        "\n",
        "predict(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'      WhiteWidow      PurpleDiesel       BlueMonster        DeadheadOg         KaliDog   '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKas4EuM0MFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#'score     Strain        \\n0.905756  B-Witched"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nej0HK52Zi2",
        "colab_type": "code",
        "outputId": "1dd972e7-e958-4aa6-ff50-4270dce76c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# user input\n",
        "user_input = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "# ominbus function\n",
        "def predict(user_input):\n",
        "\n",
        "  # install basilica\n",
        "  #!pip install basilica\n",
        "\n",
        "  import basilica\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from scipy import spatial\n",
        "\n",
        "  # get data\n",
        "  #!wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
        "  # turn data into dataframe\n",
        "  df = pd.read_csv('med1.csv')\n",
        "\n",
        "  # get pickled trained embeddings for med cultivars\n",
        "  #!wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
        "  #unpickling file of embedded cultivar descriptions\n",
        "  unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "  # Part 1\n",
        "  # maybe make a function to perform the last few steps\n",
        "\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "  # Part 4\n",
        "  output = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "  #print(output)\n",
        "  #print(output[1:])\n",
        "  output_string = str(output)\n",
        "  #print(type(output))\n",
        "  #print(output.shape)\n",
        "  #print(output_string)\n",
        "  import re\n",
        "  output_regex = re.sub(r'[^a-zA-Z ^0-9 ^.]', '', output_string)\n",
        "  #print(output_regex)\n",
        "  output_string_clipped = output_regex[50:-28]\n",
        "  #print(output_string_clipped)\n",
        "  # Part 5: output\n",
        "  return output_string_clipped\n",
        "\n",
        "predict(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 20.983573  98WhiteWidow    10.969837  PurpleDiesel     10.964103  BlueMonster      10.962950  DeadheadOg       10.961727  KaliDog      '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWnDJprr22V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#'score     Strain        0.905756  BWitched"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PItDZj5mgYC",
        "colab_type": "code",
        "outputId": "02bd6772-831c-41bc-87e6-0840cf7184bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "# user input\n",
        "user_input = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "# ominbus function\n",
        "def predict(user_input):\n",
        "\n",
        "  # install basilica\n",
        "  #!pip install basilica\n",
        "\n",
        "  import basilica\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from scipy import spatial\n",
        "\n",
        "  # get data\n",
        "  #!wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
        "  # turn data into dataframe\n",
        "  df = pd.read_csv('med1.csv')\n",
        "\n",
        "  # get pickled trained embeddings for med cultivars\n",
        "  #!wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
        "  #unpickling file of embedded cultivar descriptions\n",
        "  unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "  # Part 1\n",
        "  # maybe make a function to perform the last few steps\n",
        "\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "  # Part 4\n",
        "  output = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "  #output = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "  #print(output)\n",
        "  #print(output[1:])\n",
        "  output_string = str(output)\n",
        "  #print(type(output))\n",
        "  print(output.shape)\n",
        "  #print(output_string)\n",
        "  import re\n",
        "  output_regex = re.sub(r'[^a-zA-Z ^0-9 ^.]', '', output_string)\n",
        "  #print(output_regex)\n",
        "  output_string_clipped = output_regex[50:-28]\n",
        "  #print(output_string_clipped)\n",
        "  # Part 5: output\n",
        "  return output\n",
        "\n",
        "predict(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "score     Strain        \n",
              "0.905756  B-Witched         2\n",
              "0.983573  98-White-Widow    1\n",
              "0.969837  Purple-Diesel     1\n",
              "0.964103  Blue-Monster      1\n",
              "0.962950  Deadhead-Og       1\n",
              "0.961727  Kali-Dog          1\n",
              "Name: Strain, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QewB_KTN4vV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # json output\n",
        "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.to_json.html\n",
        "    #output_json = output.to_json(orient='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpkkEgUQ4yxP",
        "colab_type": "code",
        "outputId": "f60d6547-e624-482d-ca8a-c0669afaec84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# user input\n",
        "user_input = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "# ominbus function\n",
        "def predict(user_input):\n",
        "\n",
        "  # install basilica\n",
        "  #!pip install basilica\n",
        "\n",
        "  import basilica\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from scipy import spatial\n",
        "\n",
        "  # get data\n",
        "  #!wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
        "  # turn data into dataframe\n",
        "  df = pd.read_csv('med1.csv')\n",
        "\n",
        "  # get pickled trained embeddings for med cultivars\n",
        "  #!wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
        "  #unpickling file of embedded cultivar descriptions\n",
        "  unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "  # Part 1\n",
        "  # maybe make a function to perform the last few steps\n",
        "\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "  # Part 4\n",
        "\n",
        "  df_big_json = df.copy()\n",
        "  \n",
        "\n",
        "  #output = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "  #output = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "\n",
        "  #df_results = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "  just_id_output = df['score'].sort_values(ascending=False)\n",
        "\n",
        "  just_id_output = just_id_output.head(5)\n",
        "\n",
        "  #print(output)\n",
        "  #print(output[1:])\n",
        "  #output_string = str(output)\n",
        "  #print(type(output))\n",
        "  #print(output.shape)\n",
        "  #print(output_string)\n",
        "  import re\n",
        "  #output_regex = re.sub(r'[^a-zA-Z ^0-9 ^.]', '', output_string)\n",
        "  #print(output_regex)\n",
        "  #output_string_clipped = output_regex[50:-28]\n",
        "  #print(output_string_clipped)\n",
        "\n",
        "  # json output\n",
        "  # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.to_json.html\n",
        "  #output_json = output.to_json(orient='index')\n",
        "  #print(output_json)\n",
        "  \n",
        "  output_ID = just_id_output.to_json(orient='index')\n",
        "  #print(output_ID)\n",
        "\n",
        "  #output_json = just_id_output.to_json(orient='split')\n",
        "  #print(output_json)\n",
        "\n",
        "  #output_values_series = pd.Series(output_json)\n",
        "  #print(output_values_series)\n",
        "\n",
        "  #output_json = output_string_clipped.to_json(orient='split')\n",
        "  #print(output_json)\n",
        "\n",
        "  #print(type(output_json))\n",
        "  #print(*output_json)\n",
        "  #output_json = output.to_json(orient='records')\n",
        "  #print(output_json)\n",
        "  #output_json = output.to_json(orient='columns')\n",
        "  #print(output_json)\n",
        "  #output_json = output.to_json(orient='values')\n",
        "  #print(output_json)\n",
        "  #output_json = output.to_json(orient='key')\n",
        "  #print(output_json)\n",
        "\n",
        "  # Part 5: output\n",
        "  return output_ID\n",
        "\n",
        "predict(user_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"1\":0.9835731748,\"1682\":0.9698372559,\"304\":0.9641033337,\"644\":0.9629495883,\"1163\":0.9617265437}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPlKYW5J3tM1",
        "colab_type": "text"
      },
      "source": [
        "# This is the final requested version for Flavour-Effects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3ZtF6Hd0RDb",
        "colab_type": "code",
        "outputId": "87910ac4-1a53-485b-a4de-9ac3efee9ddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# user input\n",
        "user_input_effects = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "# ominbus function\n",
        "def predict_effects(user_input_effects):\n",
        "\n",
        "  # install basilica\n",
        "  #!pip install basilica\n",
        "\n",
        "  import basilica\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from scipy import spatial\n",
        "\n",
        "  # get data\n",
        "  #!wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
        "  # turn data into dataframe\n",
        "  df = pd.read_csv('med1.csv')\n",
        "\n",
        "  # get pickled trained embeddings for med cultivars\n",
        "  #!wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
        "  #unpickling file of embedded cultivar descriptions\n",
        "  unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "  # Part 1\n",
        "  # maybe make a function to perform the last few steps\n",
        "\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "  # Part 4\n",
        "  df_big_json = df['score'].sort_values(ascending=False)\n",
        "  df_big_json = df.copy()\n",
        "  # https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/\n",
        "  df_big_json = df_big_json[:5]\n",
        "  df_big_json = df_big_json.to_json(orient='columns')\n",
        "\n",
        "  # Part 5: output\n",
        "  return df_big_json\n",
        "\n",
        "predict_effects(user_input_effects)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Strain\":{\"0\":\"100-Og\",\"1\":\"98-White-Widow\",\"2\":\"1024\",\"3\":\"13-Dawgs\",\"4\":\"24K-Gold\"},\"Type\":{\"0\":\"hybrid\",\"1\":\"hybrid\",\"2\":\"sativa\",\"3\":\"hybrid\",\"4\":\"hybrid\"},\"Rating\":{\"0\":4.0,\"1\":4.7,\"2\":4.4,\"3\":4.2,\"4\":4.6},\"Effects\":{\"0\":\"Creative,Energetic,Tingly,Euphoric,Relaxed\",\"1\":\"Relaxed,Aroused,Creative,Happy,Energetic\",\"2\":\"Uplifted,Happy,Relaxed,Energetic,Creative\",\"3\":\"Tingly,Creative,Hungry,Relaxed,Uplifted\",\"4\":\"Happy,Relaxed,Euphoric,Uplifted,Talkative\"},\"Flavor\":{\"0\":\"Earthy,Sweet,Citrus\",\"1\":\"Flowery,Violet,Diesel\",\"2\":\"Spicy\\\\/Herbal,Sage,Woody\",\"3\":\"Apricot,Citrus,Grapefruit\",\"4\":\"Citrus,Earthy,Orange\"},\"Description\":{\"0\":\"$100 OG is a 50\\\\/50 hybrid strain that packs a strong punch. The name supposedly refers to both its strength and high price when it first started showing up in Hollywood. As a plant, $100 OG tends to produce large dark green buds with few stems. Users report a strong body effect of an indica for pain relief with the more alert, cerebral feeling thanks to its sativa side.\",\"1\":\"The \\\\u201898 Aloha White Widow is an especially potent cut of White Widow that has grown in renown alongside Hawaiian legends like Maui Wowie and Kona Gold. This White Widow phenotype reeks of diesel and skunk and has a rich earthy taste with intermittent notes of hash. Its buds are coated in trichomes, giving its dark foliage a lustrous glint to go along with its room-filling odor. This one-hitter-quitter uplifts the mind with mind-bending euphoria that materializes in the body as airy relaxation. \\\\u201898 Aloha White Widow is available from Pua Mana 1st Hawaiian Pakal\\\\u014dl\\\\u014d Seed Bank. \\\\u00a0\",\"2\":\"1024 is a sativa-dominant hybrid bred in Spain by Medical Seeds Co. The breeders claim to guard the secret genetics due to security reasons, but regardless of its genetic heritage, 1024 is a THC powerhouse with a sweet and spicy bouquet. Subtle fruit flavors mix with an herbal musk to produce uplifting sativa effects. One specific phenotype is noted for having a pungent odor that fills a room, similar to burning incense.\",\"3\":\"13 Dawgs is a hybrid of G13 and Chemdawg genetics bred by Canadian LP Delta 9 BioTech. The two potent strains mix to create a balance between indica and sativa effects. 13 Dawgs has a sweet earthy musk that brings a blend of woody\\\\u00a0citrus flavors. The effects of 13 Dawgs induce a happy, relaxed body buzz with a creative and focused mind that counters depression and stimulates the appetite.\",\"4\":\"Also known as Kosher Tangie, 24k Gold is a 60% indica-dominant hybrid that combines the legendary LA strain Kosher Kush with champion sativa Tangie to create something quite unique. Growing tall in its vegetative cycle and very stretchy in flower, this one will need an experienced hand when grown indoors. Most phenotypes will exhibit a sweet orange aroma from the Tangie along with the dark coloration of the Kosher Kush, and will offer a strong citrus flavor when smoked or vaped. THC levels range from 18% to 24%; definitely not for novice users!\\\\u00a0\"},\"score\":{\"0\":0.8958629381,\"1\":0.9835731748,\"2\":0.9267263907,\"3\":0.8898603618,\"4\":0.9143115221}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT2K469y4Xu7",
        "colab_type": "text"
      },
      "source": [
        "# This is the final requested version for symptoms-diseases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtGPy2qg4kP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8ePD_KD4SFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# user input\n",
        "user_input_symptom = \"pain\"\n",
        "\n",
        "# ominbus function\n",
        "def predict_symptom(user_input):\n",
        "\n",
        "  # install basilica\n",
        "  #!pip install basilica\n",
        "\n",
        "  import basilica\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from scipy import spatial\n",
        "\n",
        "  # get data\n",
        "  #!wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
        "  # turn data into dataframe\n",
        "  df = pd.read_csv('med1.csv')\n",
        "\n",
        "  # get pickled trained embeddings for med cultivars\n",
        "  #!wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
        "  #unpickling file of embedded cultivar descriptions\n",
        "  #unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "  unpickled_df_test2 = pd.read_pickle(\"./symptommedembedv1.pkl\")\n",
        "\n",
        "  # Part 1\n",
        "  # maybe make a function to perform the last few steps\n",
        "\n",
        "  # a function to calculate_user_text_embedding\n",
        "  # to save the embedding value in session memory\n",
        "  user_input_embedding2 = 0\n",
        "\n",
        "  def calculate_user_text_embedding(input, user_input_embedding2):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "      user_input_embedding = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding2\n",
        "\n",
        "  # run the function to save the embedding value in session memory\n",
        "  user_input_embedding2 = calculate_user_text_embedding(user_input, user_input_embedding2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # part 2\n",
        "  score = 0\n",
        "\n",
        "  def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored2 = unpickled_df_test2.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored2, user_input_embedding2)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "  # Part 3\n",
        "  for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input2, score, i, user_input_embedding2)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "  # Part 4\n",
        "  df_big_json = df['score'].sort_values(ascending=False)\n",
        "  df_big_json = df.copy()\n",
        "  # https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/\n",
        "  df_big_json = df_big_json[:5]\n",
        "  df_big_json = df_big_json.to_json(orient='columns')\n",
        "\n",
        "  # Part 5: output\n",
        "  return df_big_json\n",
        "\n",
        "predict_symptom(user_input_symptom)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqMsGiky4SS_",
        "colab_type": "code",
        "outputId": "1121e8d3-e922-4c1b-dca8-d6341c2b6492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "# less mess output\n",
        "# install basilica\n",
        "\n",
        "import basilica\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import spatial\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "#!pip install basilica\n",
        "#!wget https://github.com/lineality/4.4_Build_files/raw/master/symptommedembedv1.pkl\n",
        "#!wget https://github.com/lineality/4.4_Build_files/raw/master/symptoms2_medcab3.csv\n",
        "\n",
        "# user input\n",
        "user_input_symptom = \"pain\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ominbus function\n",
        "def predict_symptom(user_input_symptom):\n",
        "\n",
        "    # turn data into dataframe\n",
        "    df = pd.read_csv('symptoms2_medcab3.csv')\n",
        "    \n",
        "    # get pickled trained embeddings for med cultivars\n",
        "    unpickled_df_test2 = pd.read_pickle(\"./symptommedembedv1.pkl\")\n",
        "\n",
        "    # Part 1\n",
        "    # maybe make a function to perform the last few steps\n",
        "    # a function to calculate_user_text_embedding\n",
        "    # to save the embedding value in session memory\n",
        "    user_input_embedding2 = 0\n",
        "\n",
        "    def calculate_user_text_embedding(input, user_input_embedding2):\n",
        "\n",
        "        # setting a string of two sentences for the algo to compare\n",
        "        sentences = [input]\n",
        "\n",
        "        # calculating embedding for both user_entered_text and for features\n",
        "        with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "            user_input_embedding = list(c.embed_sentences(sentences))\n",
        "        \n",
        "        return user_input_embedding2\n",
        "\n",
        "    # run the function to save the embedding value in session memory\n",
        "    user_input_embedding2 = calculate_user_text_embedding(user_input_symptom, user_input_embedding2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # part 2\n",
        "    score = 0\n",
        "\n",
        "    def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "        # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "        embedding_stored2 = unpickled_df_test2.loc[row1, 0]\n",
        "        \n",
        "        # calculates the similarity of user_text vs. product description\n",
        "        score = 1 - spatial.distance.cosine(embedding_stored2, user_input_embedding2)\n",
        "\n",
        "        # returns a variable that can be used outside of the function\n",
        "        return score\n",
        "\n",
        "\n",
        "    # Part 3\n",
        "    for i in range(2351):\n",
        "        # calls the function to set the value of 'score'\n",
        "        # which is the score of the user input\n",
        "        score = score_user_input_from_stored_embedding_from_stored_values(user_input_symptom, score, i, user_input_embedding2)\n",
        "        \n",
        "        #stores the score in the dataframe\n",
        "        df.loc[i,'score'] = score\n",
        "\n",
        "    print(df.head(1))\n",
        "    # Part 4: returns all data for the top 5 results as a json obj\n",
        "    df_big_json = df['score'].sort_values(ascending=False)\n",
        "    #df_big_json = df.copy()\n",
        "    # https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/\n",
        "    df_big_json = df_big_json[:5]\n",
        "    df_big_json = df_big_json.to_json(orient='columns')\n",
        "    # Part 5: output\n",
        "    return df_big_json\n",
        "\n",
        "predict_symptom(user_input_symptom)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  Strain    Type  Rating                                     Effects               Flavor                                        Description             symptoms_diseases  score\n",
            "0           0  100-Og  hybrid     4.0  Creative,Energetic,Tingly,Euphoric,Relaxed  Earthy,Sweet,Citrus  $100 OG is a 50/50 hybrid strain that packs a ...  ms, pain, pain, spasticity,     NaN\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Unnamed: 0\":{\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"4\":4},\"Strain\":{\"0\":\"100-Og\",\"1\":\"98-White-Widow\",\"2\":\"1024\",\"3\":\"13-Dawgs\",\"4\":\"24K-Gold\"},\"Type\":{\"0\":\"hybrid\",\"1\":\"hybrid\",\"2\":\"sativa\",\"3\":\"hybrid\",\"4\":\"hybrid\"},\"Rating\":{\"0\":4.0,\"1\":4.7,\"2\":4.4,\"3\":4.2,\"4\":4.6},\"Effects\":{\"0\":\"Creative,Energetic,Tingly,Euphoric,Relaxed\",\"1\":\"Relaxed,Aroused,Creative,Happy,Energetic\",\"2\":\"Uplifted,Happy,Relaxed,Energetic,Creative\",\"3\":\"Tingly,Creative,Hungry,Relaxed,Uplifted\",\"4\":\"Happy,Relaxed,Euphoric,Uplifted,Talkative\"},\"Flavor\":{\"0\":\"Earthy,Sweet,Citrus\",\"1\":\"Flowery,Violet,Diesel\",\"2\":\"Spicy\\\\/Herbal,Sage,Woody\",\"3\":\"Apricot,Citrus,Grapefruit\",\"4\":\"Citrus,Earthy,Orange\"},\"Description\":{\"0\":\"$100 OG is a 50\\\\/50 hybrid strain that packs a strong punch. The name supposedly refers to both its strength and high price when it first started showing up in Hollywood. As a plant, $100 OG tends to produce large dark green buds with few stems. Users report a strong body effect of an indica for pain relief with the more alert, cerebral feeling thanks to its sativa side.\",\"1\":\"The \\\\u201898 Aloha White Widow is an especially potent cut of White Widow that has grown in renown alongside Hawaiian legends like Maui Wowie and Kona Gold. This White Widow phenotype reeks of diesel and skunk and has a rich earthy taste with intermittent notes of hash. Its buds are coated in trichomes, giving its dark foliage a lustrous glint to go along with its room-filling odor. This one-hitter-quitter uplifts the mind with mind-bending euphoria that materializes in the body as airy relaxation. \\\\u201898 Aloha White Widow is available from Pua Mana 1st Hawaiian Pakal\\\\u014dl\\\\u014d Seed Bank. \\\\u00a0\",\"2\":\"1024 is a sativa-dominant hybrid bred in Spain by Medical Seeds Co. The breeders claim to guard the secret genetics due to security reasons, but regardless of its genetic heritage, 1024 is a THC powerhouse with a sweet and spicy bouquet. Subtle fruit flavors mix with an herbal musk to produce uplifting sativa effects. One specific phenotype is noted for having a pungent odor that fills a room, similar to burning incense.\",\"3\":\"13 Dawgs is a hybrid of G13 and Chemdawg genetics bred by Canadian LP Delta 9 BioTech. The two potent strains mix to create a balance between indica and sativa effects. 13 Dawgs has a sweet earthy musk that brings a blend of woody\\\\u00a0citrus flavors. The effects of 13 Dawgs induce a happy, relaxed body buzz with a creative and focused mind that counters depression and stimulates the appetite.\",\"4\":\"Also known as Kosher Tangie, 24k Gold is a 60% indica-dominant hybrid that combines the legendary LA strain Kosher Kush with champion sativa Tangie to create something quite unique. Growing tall in its vegetative cycle and very stretchy in flower, this one will need an experienced hand when grown indoors. Most phenotypes will exhibit a sweet orange aroma from the Tangie along with the dark coloration of the Kosher Kush, and will offer a strong citrus flavor when smoked or vaped. THC levels range from 18% to 24%; definitely not for novice users!\\\\u00a0\"},\"symptoms_diseases\":{\"0\":\"ms, pain, pain, spasticity, \",\"1\":\"spasticity, \",\"2\":\"pain, pain, spasticity, \",\"3\":\"appetite, appetite, depression, spasticity, \",\"4\":\"spasticity, \"},\"score\":{\"0\":null,\"1\":null,\"2\":null,\"3\":null,\"4\":null}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaOHzWdPSOst",
        "colab_type": "code",
        "outputId": "a0cfebcb-f02e-4aab-9842-719effab7047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# less mess output\n",
        "# install basilica\n",
        "\n",
        "\n",
        "#!pip install basilica\n",
        "#!wget https://github.com/lineality/4.4_Build_files/raw/master/symptommedembedv1.pkl\n",
        "#!wget https://github.com/lineality/4.4_Build_files/raw/master/symptoms2_medcab3.csv\n",
        "\n",
        "import basilica\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import spatial\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "\n",
        "# user input\n",
        "user_input_symptom = \"spasticity\"\n",
        "\n",
        "\n",
        "# ominbus function\n",
        "def predict_symptom(user_input_symptom):\n",
        "\n",
        "    # turn data into dataframe\n",
        "    df = pd.read_csv('symptoms2_medcab3.csv')\n",
        "    \n",
        "    # get pickled trained embeddings for med cultivars\n",
        "    unpickled_df_test2 = pd.read_pickle(\"./symptommedembedv1.pkl\")\n",
        "\n",
        "    # Part 1\n",
        "    # maybe make a function to perform the last few steps\n",
        "    # a function to calculate_user_text_embedding\n",
        "    # to save the embedding value in session memory\n",
        "    user_input_embedding2 = 0\n",
        "\n",
        "    def calculate_user_text_embedding(input, user_input_embedding2):\n",
        "\n",
        "        # setting a string of two sentences for the algo to compare\n",
        "        sentences = [input]\n",
        "\n",
        "        # calculating embedding for both user_entered_text and for features\n",
        "        with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "            user_input_embedding = list(c.embed_sentences(sentences))\n",
        "        \n",
        "        return user_input_embedding2\n",
        "\n",
        "    # run the function to save the embedding value in session memory\n",
        "    user_input_embedding2 = calculate_user_text_embedding(user_input_symptom, user_input_embedding2)\n",
        "\n",
        "\n",
        "\n",
        "    # part 2\n",
        "    score = 0\n",
        "\n",
        "    def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "        # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "        embedding_stored2 = unpickled_df_test2.loc[row1, 0]\n",
        "        \n",
        "        # calculates the similarity of user_text vs. product description\n",
        "        score = 1 - spatial.distance.cosine(embedding_stored2, user_input_embedding2)\n",
        "\n",
        "        # returns a variable that can be used outside of the function\n",
        "        return score\n",
        "\n",
        "\n",
        "    # Part 3\n",
        "    for i in range(2351):\n",
        "        # calls the function to set the value of 'score'\n",
        "        # which is the score of the user input\n",
        "        score = score_user_input_from_stored_embedding_from_stored_values(user_input_symptom, score, i, user_input_embedding2)\n",
        "        \n",
        "        #stores the score in the dataframe\n",
        "        df.loc[i,'score'] = score\n",
        "\n",
        "    #print(df.head(1))\n",
        "    top_five = df.copy()\n",
        "    # https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/\n",
        "    top_five = top_five[:5]\n",
        "    top_five = top_five['Strain'].values\n",
        "    top_five\n",
        "    # Part 5: output\n",
        "\n",
        "    return top_five\n",
        "\n",
        "predict_symptom(user_input_symptom)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['100-Og', '98-White-Widow', '1024', '13-Dawgs', '24K-Gold'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl4ITNGp4SRC",
        "colab_type": "code",
        "outputId": "afcbb7c8-2eed-4b89-8e19-45cb5e182f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        }
      },
      "source": [
        "df.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Strain</th>\n",
              "      <th>Type</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Effects</th>\n",
              "      <th>Flavor</th>\n",
              "      <th>Description</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100-Og</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Creative,Energetic,Tingly,Euphoric,Relaxed</td>\n",
              "      <td>Earthy,Sweet,Citrus</td>\n",
              "      <td>$100 OG is a 50/50 hybrid strain that packs a ...</td>\n",
              "      <td>0.867627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Strain    Type  Rating                                     Effects               Flavor                                        Description     score\n",
              "0  100-Og  hybrid     4.0  Creative,Energetic,Tingly,Euphoric,Relaxed  Earthy,Sweet,Citrus  $100 OG is a 50/50 hybrid strain that packs a ...  0.867627"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEHWRNpO4SPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    df_big_json = df['score'].sort_values(ascending=False)\n",
        "    df_big_json = df.copy()\n",
        "    # https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/\n",
        "    df_big_json = df_big_json[:5]\n",
        "    df_big_json = df_big_json.to_json(orient='columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEKeTGnn4SMi",
        "colab_type": "code",
        "outputId": "4c45213e-60b4-4b3e-9533-7adc8f831e7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "df_big_json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Strain\":{\"0\":\"100-Og\",\"1\":\"98-White-Widow\",\"2\":\"1024\",\"3\":\"13-Dawgs\",\"4\":\"24K-Gold\"},\"Type\":{\"0\":\"hybrid\",\"1\":\"hybrid\",\"2\":\"sativa\",\"3\":\"hybrid\",\"4\":\"hybrid\"},\"Rating\":{\"0\":4.0,\"1\":4.7,\"2\":4.4,\"3\":4.2,\"4\":4.6},\"Effects\":{\"0\":\"Creative,Energetic,Tingly,Euphoric,Relaxed\",\"1\":\"Relaxed,Aroused,Creative,Happy,Energetic\",\"2\":\"Uplifted,Happy,Relaxed,Energetic,Creative\",\"3\":\"Tingly,Creative,Hungry,Relaxed,Uplifted\",\"4\":\"Happy,Relaxed,Euphoric,Uplifted,Talkative\"},\"Flavor\":{\"0\":\"Earthy,Sweet,Citrus\",\"1\":\"Flowery,Violet,Diesel\",\"2\":\"Spicy\\\\/Herbal,Sage,Woody\",\"3\":\"Apricot,Citrus,Grapefruit\",\"4\":\"Citrus,Earthy,Orange\"},\"Description\":{\"0\":\"$100 OG is a 50\\\\/50 hybrid strain that packs a strong punch. The name supposedly refers to both its strength and high price when it first started showing up in Hollywood. As a plant, $100 OG tends to produce large dark green buds with few stems. Users report a strong body effect of an indica for pain relief with the more alert, cerebral feeling thanks to its sativa side.\",\"1\":\"The \\\\u201898 Aloha White Widow is an especially potent cut of White Widow that has grown in renown alongside Hawaiian legends like Maui Wowie and Kona Gold. This White Widow phenotype reeks of diesel and skunk and has a rich earthy taste with intermittent notes of hash. Its buds are coated in trichomes, giving its dark foliage a lustrous glint to go along with its room-filling odor. This one-hitter-quitter uplifts the mind with mind-bending euphoria that materializes in the body as airy relaxation. \\\\u201898 Aloha White Widow is available from Pua Mana 1st Hawaiian Pakal\\\\u014dl\\\\u014d Seed Bank. \\\\u00a0\",\"2\":\"1024 is a sativa-dominant hybrid bred in Spain by Medical Seeds Co. The breeders claim to guard the secret genetics due to security reasons, but regardless of its genetic heritage, 1024 is a THC powerhouse with a sweet and spicy bouquet. Subtle fruit flavors mix with an herbal musk to produce uplifting sativa effects. One specific phenotype is noted for having a pungent odor that fills a room, similar to burning incense.\",\"3\":\"13 Dawgs is a hybrid of G13 and Chemdawg genetics bred by Canadian LP Delta 9 BioTech. The two potent strains mix to create a balance between indica and sativa effects. 13 Dawgs has a sweet earthy musk that brings a blend of woody\\\\u00a0citrus flavors. The effects of 13 Dawgs induce a happy, relaxed body buzz with a creative and focused mind that counters depression and stimulates the appetite.\",\"4\":\"Also known as Kosher Tangie, 24k Gold is a 60% indica-dominant hybrid that combines the legendary LA strain Kosher Kush with champion sativa Tangie to create something quite unique. Growing tall in its vegetative cycle and very stretchy in flower, this one will need an experienced hand when grown indoors. Most phenotypes will exhibit a sweet orange aroma from the Tangie along with the dark coloration of the Kosher Kush, and will offer a strong citrus flavor when smoked or vaped. THC levels range from 18% to 24%; definitely not for novice users!\\\\u00a0\"},\"score\":{\"0\":0.8676269136,\"1\":0.8103575001,\"2\":0.8733667797,\"3\":0.8450572921,\"4\":0.8103575001}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "marNgTiV4SKR",
        "colab_type": "code",
        "outputId": "16447ff7-35e3-4e7d-ca00-d5febcaede73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "top_five = df.copy()\n",
        "# https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/\n",
        "top_five = df_big_json[:5]\n",
        "top_five = top_five['Strain'].values\n",
        "top_five"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['100-Og', '98-White-Widow', '1024', '13-Dawgs', '24K-Gold'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X_2dYRN4SIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_nm6u8I4SDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cOEKKwaRIUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flask import request\n",
        "import pickle \n",
        "​\n",
        "@app.route(\"/swords\", methods=['POST'])\n",
        "def swords():\n",
        "    ''' a route, expects json object with 2 keys'''\n",
        "    \n",
        "    # receive input\n",
        "    lines = request.get_json(force=True)\n",
        "    \n",
        "    # get data from json\n",
        "    blessed_blade = lines['thunderfury'] # json keys that backend abides\n",
        "​    ashbringer = lines['corrupted'] \n",
        "\n",
        "    # validate input (optional)\n",
        "    assert isinstance(blessed_blade, int)\n",
        "    assert isinstance(ashbringer, str)\n",
        "    \n",
        "    # deserialize the pretrained model. \n",
        "    with open('model.pickle', 'rb') as mod: \n",
        "        model = pickle.load(mod)\n",
        "    \n",
        "    # predict\n",
        "    output = model.predict([[blessed_blade, ashbringer]])\n",
        "    \n",
        "    # use a dictionary to format output for json\n",
        "    send_back = {'prediction': output}\n",
        "    send_back_dummy = {'dummy': 1} # minimal functionality for testing\n",
        "    send_back_input = { # verify that input is working as expected\n",
        "        'blessed_blade': blessed_blade, \n",
        "        'ashbringer': ashbringer\n",
        "        }\n",
        "    \n",
        "    # give output to sender.\n",
        "    return app.response_class(\n",
        "        response=json.dumps(send_back),\n",
        "        status=200,\n",
        "        mimetype='application/json'\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDDPonzuVxk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flask import request\n",
        "import pickle \n",
        "​\n",
        "# user input\n",
        "user_input = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "# ominbus function\n",
        "def predict(user_input):\n",
        "\n",
        "    # install basilica\n",
        "    #!pip install basilica\n",
        "\n",
        "    import basilica\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from scipy import spatial\n",
        "\n",
        "    # get data\n",
        "    #!wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
        "    # turn data into dataframe\n",
        "    df = pd.read_csv('med1.csv')\n",
        "\n",
        "    # get pickled trained embeddings for med cultivars\n",
        "    #!wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
        "    #unpickling file of embedded cultivar descriptions\n",
        "    unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "    # Part 1\n",
        "    # maybe make a function to perform the last few steps\n",
        "\n",
        "    # a function to calculate_user_text_embedding\n",
        "    # to save the embedding value in session memory\n",
        "    user_input_embedding = 0\n",
        "\n",
        "    def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "        # setting a string of two sentences for the algo to compare\n",
        "        sentences = [input]\n",
        "\n",
        "        # calculating embedding for both user_entered_text and for features\n",
        "        with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "          user_input_embedding = list(c.embed_sentences(sentences))\n",
        "        \n",
        "        return user_input_embedding\n",
        "\n",
        "    # run the function to save the embedding value in session memory\n",
        "    user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # part 2\n",
        "    score = 0\n",
        "\n",
        "    def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "        # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "        embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "        \n",
        "        # calculates the similarity of user_text vs. product description\n",
        "        score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "        # returns a variable that can be used outside of the function\n",
        "        return score\n",
        "\n",
        "\n",
        "    # Part 3\n",
        "    for i in range(2351):\n",
        "        # calls the function to set the value of 'score'\n",
        "        # which is the score of the user input\n",
        "        score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "        \n",
        "        #stores the score in the dataframe\n",
        "        df.loc[i,'score'] = score\n",
        "\n",
        "    # Part 4\n",
        "    #output = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "    #output = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "\n",
        "    #df_results = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "    just_id_output = df['score'].sort_values(ascending=False)\n",
        "\n",
        "    just_id_output = just_id_output.head(5)\n",
        "\n",
        "    #print(output)\n",
        "    #print(output[1:])\n",
        "    #output_string = str(output)\n",
        "    #print(type(output))\n",
        "    #print(output.shape)\n",
        "    #print(output_string)\n",
        "    import re\n",
        "    #output_regex = re.sub(r'[^a-zA-Z ^0-9 ^.]', '', output_string)\n",
        "    #print(output_regex)\n",
        "    #output_string_clipped = output_regex[50:-28]\n",
        "    #print(output_string_clipped)\n",
        "\n",
        "    # json output\n",
        "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.to_json.html\n",
        "    #output_json = output.to_json(orient='index')\n",
        "    #print(output_json)\n",
        "    \n",
        "    output_ID = just_id_output.to_json(orient='index')\n",
        "    #print(output_ID)\n",
        "\n",
        "    #output_json = just_id_output.to_json(orient='split')\n",
        "    #print(output_json)\n",
        "\n",
        "    #output_values_series = pd.Series(output_json)\n",
        "    #print(output_values_series)\n",
        "\n",
        "    #output_json = output_string_clipped.to_json(orient='split')\n",
        "    #print(output_json)\n",
        "\n",
        "    #print(type(output_json))\n",
        "    #print(*output_json)\n",
        "    #output_json = output.to_json(orient='records')\n",
        "    #print(output_json)\n",
        "    #output_json = output.to_json(orient='columns')\n",
        "    #print(output_json)\n",
        "    #output_json = output.to_json(orient='values')\n",
        "    #print(output_json)\n",
        "    #output_json = output.to_json(orient='key')\n",
        "    #print(output_json)\n",
        "\n",
        "    # Part 5: output\n",
        "    return output_ID\n",
        "\n",
        "\n",
        "\n",
        "@app.route(\"/swords\", methods=['POST'])\n",
        "def swords():\n",
        "    ''' a route, expects json object with 2 keys'''\n",
        "    \n",
        "    # receive input\n",
        "    lines = request.get_json(force=True)\n",
        "    \n",
        "    # get data from json\n",
        "    blessed_blade = lines['thunderfury'] # json keys that backend abides\n",
        "​    ashbringer = lines['corrupted'] \n",
        "\n",
        "    # validate input (optional)\n",
        "    assert isinstance(blessed_blade, int)\n",
        "    assert isinstance(ashbringer, str)\n",
        "    \n",
        "    # deserialize the pretrained model. \n",
        "    with open('model.pickle', 'rb') as mod: \n",
        "        model = pickle.load(mod)\n",
        "    \n",
        "    # old predict\n",
        "    #output = model.predict([[blessed_blade, ashbringer]])\n",
        "    \n",
        "    # new predict\n",
        "\n",
        "    output = predict(user_input)\n",
        "\n",
        "    # use a dictionary to format output for json\n",
        "    send_back = {'prediction': output}\n",
        "    send_back_dummy = {'dummy': 1} # minimal functionality for testing\n",
        "    send_back_input = { # verify that input is working as expected\n",
        "        'blessed_blade': blessed_blade, \n",
        "        'ashbringer': ashbringer\n",
        "        }\n",
        "    \n",
        "    # give output to sender.\n",
        "    return app.response_class(\n",
        "        response=json.dumps(send_back),\n",
        "        status=200,\n",
        "        mimetype='application/json'\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLlJPgjJ6DMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i48KeC4tV_Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# user input\n",
        "user_input_effect = \"text, Relaxed, Violet, Aroused, Creative, Happy, Energetic, Flowery, Diesel\"\n",
        "\n",
        "# ominbus function\n",
        "def predict_effect(user_input):\n",
        "\n",
        "    # install basilica\n",
        "    #!pip install basilica\n",
        "\n",
        "    import basilica\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from scipy import spatial\n",
        "\n",
        "    # get data\n",
        "    #!wget https://raw.githubusercontent.com/MedCabinet/ML_Machine_Learning_Files/master/med1.csv\n",
        "    # turn data into dataframe\n",
        "    df = pd.read_csv('med1.csv')\n",
        "\n",
        "    # get pickled trained embeddings for med cultivars\n",
        "    #!wget https://github.com/lineality/4.4_Build_files/raw/master/medembedv2.pkl\n",
        "    #unpickling file of embedded cultivar descriptions\n",
        "    unpickled_df_test = pd.read_pickle(\"./medembedv2.pkl\")\n",
        "\n",
        "\n",
        "    # Part 1\n",
        "    # maybe make a function to perform the last few steps\n",
        "\n",
        "    # a function to calculate_user_text_embedding\n",
        "    # to save the embedding value in session memory\n",
        "    user_input_embedding = 0\n",
        "\n",
        "    def calculate_user_text_embedding(input, user_input_embedding):\n",
        "\n",
        "        # setting a string of two sentences for the algo to compare\n",
        "        sentences = [input]\n",
        "\n",
        "        # calculating embedding for both user_entered_text and for features\n",
        "        with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "            user_input_embedding = list(c.embed_sentences(sentences))\n",
        "        \n",
        "        return user_input_embedding\n",
        "\n",
        "    # run the function to save the embedding value in session memory\n",
        "    user_input_embedding = calculate_user_text_embedding(user_input, user_input_embedding)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # part 2\n",
        "    score = 0\n",
        "\n",
        "    def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "        # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "        embedding_stored = unpickled_df_test.loc[row1, 0]\n",
        "        \n",
        "        # calculates the similarity of user_text vs. product description\n",
        "        score = 1 - spatial.distance.cosine(embedding_stored, user_input_embedding)\n",
        "\n",
        "        # returns a variable that can be used outside of the function\n",
        "        return score\n",
        "\n",
        "\n",
        "    # Part 3\n",
        "    for i in range(2351):\n",
        "        # calls the function to set the value of 'score'\n",
        "        # which is the score of the user input\n",
        "        score = score_user_input_from_stored_embedding_from_stored_values(user_input, score, i, user_input_embedding)\n",
        "        \n",
        "        #stores the score in the dataframe\n",
        "        df.loc[i,'score'] = score\n",
        "\n",
        "    # Part 4\n",
        "    #output = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "    #output = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "\n",
        "    #df_results = df['Strain'].groupby(df['score']).value_counts().nlargest(6, keep='last')\n",
        "    just_id_output = df['score'].sort_values(ascending=False)\n",
        "\n",
        "    just_id_output = just_id_output.head(5)\n",
        "\n",
        "    #print(output)\n",
        "    #print(output[1:])\n",
        "    #output_string = str(output)\n",
        "    #print(type(output))\n",
        "    #print(output.shape)\n",
        "    #print(output_string)\n",
        "    import re\n",
        "    #output_regex = re.sub(r'[^a-zA-Z ^0-9 ^.]', '', output_string)\n",
        "    #print(output_regex)            \n",
        "    #output_string_clipped = output_regex[50:-28]\n",
        "    #print(output_string_clipped)\n",
        "\n",
        "    # json output\n",
        "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.to_json.html\n",
        "    #output_json = output.to_json(orient='index')\n",
        "    #print(output_json)\n",
        "    \n",
        "    output_ID = just_id_output.to_json(orient='index')\n",
        "    #print(output_ID)\n",
        "\n",
        "    #output_json = just_id_output.to_json(orient='split')\n",
        "    #print(output_json)\n",
        "\n",
        "    #output_values_series = pd.Series(output_json)\n",
        "    #print(output_values_series)\n",
        "\n",
        "    #output_json = output_string_clipped.to_json(orient='split')\n",
        "    #print(output_json)\n",
        "\n",
        "    #print(type(output_json))\n",
        "    #print(*output_json)\n",
        "    #output_json = output.to_json(orient='records')\n",
        "    #print(output_json)\n",
        "    #output_json = output.to_json(orient='columns')\n",
        "    #print(output_json)\n",
        "    #output_json = output.to_json(orient='values')\n",
        "    #print(output_json)\n",
        "    #output_json = output.to_json(orient='key')\n",
        "    #print(output_json)\n",
        "\n",
        "    # Part 5: output\n",
        "    return output_ID\n",
        "\n",
        "predict_effect(user_input_effect)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCbh-XrW6KMU",
        "colab_type": "text"
      },
      "source": [
        "# big output function1 flavours effects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIWf3U2t6JnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7soeJeR57po",
        "colab_type": "text"
      },
      "source": [
        "#symptom function with 4 spaces to the tab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxOr18ux58Ax",
        "colab_type": "code",
        "outputId": "0bd985f5-a79f-418e-c472-1579949f6ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# install basilica\n",
        "#!pip install basilica\n",
        "import basilica\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import spatial\n",
        "\n",
        "#!wget https://github.com/lineality/4.4_Build_files/raw/master/symptommedembedv2.pkl\n",
        "#!wget https://github.com/lineality/4.4_Build_files/raw/master/symptoms2_medcab3.csv\n",
        "\n",
        "# user input\n",
        "user_input_symptom = \"pain\"\n",
        "\n",
        "\n",
        "\n",
        "# ominbus function\n",
        "def predict_symptom(user_input_symptom):\n",
        "\n",
        "    # get pickled trained embeddings for med cultivars\n",
        "    unpickled_df_test2 = pd.read_pickle(\"./symptommedembedv2.pkl\")\n",
        "\n",
        "    # turn data into dataframe\n",
        "    df = pd.read_csv('symptoms2_medcab3.csv')\n",
        "\n",
        "    # Part 1\n",
        "    # maybe make a function to perform the last few steps\n",
        "    # a function to calculate_user_text_embedding\n",
        "    # to save the embedding value in session memory\n",
        "    user_input_embedding2 = 0\n",
        "\n",
        "    def calculate_user_text_embedding(input, user_input_embedding2):\n",
        "\n",
        "        # setting a string of two sentences for the algo to compare\n",
        "        sentences = [input]\n",
        "\n",
        "        # calculating embedding for both user_entered_text and for features\n",
        "        with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "            user_input_embedding = list(c.embed_sentences(sentences))\n",
        "        \n",
        "        return user_input_embedding2\n",
        "\n",
        "    # run the function to save the embedding value in session memory\n",
        "    user_input_embedding2 = calculate_user_text_embedding(user_input_symptom, user_input_embedding2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # part 2\n",
        "    score = 0\n",
        "\n",
        "    def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding):\n",
        "\n",
        "        # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "        embedding_stored2 = unpickled_df_test2.loc[row1, 0]\n",
        "        \n",
        "        # calculates the similarity of user_text vs. product description\n",
        "        score = 1 - spatial.distance.cosine(embedding_stored2, user_input_embedding2)\n",
        "\n",
        "        # returns a variable that can be used outside of the function\n",
        "        return score\n",
        "\n",
        "\n",
        "\n",
        "    # Part 3\n",
        "    for i in range(2351):\n",
        "        # calls the function to set the value of 'score'\n",
        "        # which is the score of the user input\n",
        "        score = score_user_input_from_stored_embedding_from_stored_values(user_input_symptom, score, i, user_input_embedding2)\n",
        "        \n",
        "        #stores the score in the dataframe\n",
        "        df.loc[i,'score'] = score\n",
        "\n",
        "    # Part 4: returns all data for the top 5 results as a json obj\n",
        "    df_big_json = df['score'].sort_values(ascending=False)\n",
        "    df_big_json = df.copy()\n",
        "    df_big_json = df_big_json[:5]\n",
        "    df_big_json = df_big_json.to_json(orient='columns')\n",
        "\n",
        "    # Part 5: output\n",
        "    return df_big_json\n",
        "\n",
        "predict_symptom(user_input_symptom)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Unnamed: 0\":{\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"4\":4},\"Strain\":{\"0\":\"100-Og\",\"1\":\"98-White-Widow\",\"2\":\"1024\",\"3\":\"13-Dawgs\",\"4\":\"24K-Gold\"},\"Type\":{\"0\":\"hybrid\",\"1\":\"hybrid\",\"2\":\"sativa\",\"3\":\"hybrid\",\"4\":\"hybrid\"},\"Rating\":{\"0\":4.0,\"1\":4.7,\"2\":4.4,\"3\":4.2,\"4\":4.6},\"Effects\":{\"0\":\"Creative,Energetic,Tingly,Euphoric,Relaxed\",\"1\":\"Relaxed,Aroused,Creative,Happy,Energetic\",\"2\":\"Uplifted,Happy,Relaxed,Energetic,Creative\",\"3\":\"Tingly,Creative,Hungry,Relaxed,Uplifted\",\"4\":\"Happy,Relaxed,Euphoric,Uplifted,Talkative\"},\"Flavor\":{\"0\":\"Earthy,Sweet,Citrus\",\"1\":\"Flowery,Violet,Diesel\",\"2\":\"Spicy\\\\/Herbal,Sage,Woody\",\"3\":\"Apricot,Citrus,Grapefruit\",\"4\":\"Citrus,Earthy,Orange\"},\"Description\":{\"0\":\"$100 OG is a 50\\\\/50 hybrid strain that packs a strong punch. The name supposedly refers to both its strength and high price when it first started showing up in Hollywood. As a plant, $100 OG tends to produce large dark green buds with few stems. Users report a strong body effect of an indica for pain relief with the more alert, cerebral feeling thanks to its sativa side.\",\"1\":\"The \\\\u201898 Aloha White Widow is an especially potent cut of White Widow that has grown in renown alongside Hawaiian legends like Maui Wowie and Kona Gold. This White Widow phenotype reeks of diesel and skunk and has a rich earthy taste with intermittent notes of hash. Its buds are coated in trichomes, giving its dark foliage a lustrous glint to go along with its room-filling odor. This one-hitter-quitter uplifts the mind with mind-bending euphoria that materializes in the body as airy relaxation. \\\\u201898 Aloha White Widow is available from Pua Mana 1st Hawaiian Pakal\\\\u014dl\\\\u014d Seed Bank. \\\\u00a0\",\"2\":\"1024 is a sativa-dominant hybrid bred in Spain by Medical Seeds Co. The breeders claim to guard the secret genetics due to security reasons, but regardless of its genetic heritage, 1024 is a THC powerhouse with a sweet and spicy bouquet. Subtle fruit flavors mix with an herbal musk to produce uplifting sativa effects. One specific phenotype is noted for having a pungent odor that fills a room, similar to burning incense.\",\"3\":\"13 Dawgs is a hybrid of G13 and Chemdawg genetics bred by Canadian LP Delta 9 BioTech. The two potent strains mix to create a balance between indica and sativa effects. 13 Dawgs has a sweet earthy musk that brings a blend of woody\\\\u00a0citrus flavors. The effects of 13 Dawgs induce a happy, relaxed body buzz with a creative and focused mind that counters depression and stimulates the appetite.\",\"4\":\"Also known as Kosher Tangie, 24k Gold is a 60% indica-dominant hybrid that combines the legendary LA strain Kosher Kush with champion sativa Tangie to create something quite unique. Growing tall in its vegetative cycle and very stretchy in flower, this one will need an experienced hand when grown indoors. Most phenotypes will exhibit a sweet orange aroma from the Tangie along with the dark coloration of the Kosher Kush, and will offer a strong citrus flavor when smoked or vaped. THC levels range from 18% to 24%; definitely not for novice users!\\\\u00a0\"},\"symptoms_diseases\":{\"0\":\"ms, pain, pain, spasticity, \",\"1\":\"spasticity, \",\"2\":\"pain, pain, spasticity, \",\"3\":\"appetite, appetite, depression, spasticity, \",\"4\":\"spasticity, \"},\"score\":{\"0\":null,\"1\":null,\"2\":null,\"3\":null,\"4\":null}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYG8M0NJsJjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get pickled trained embeddings for med cultivars\n",
        "unpickled_df_test2 = pd.read_pickle(\"./symptommedembedv2.pkl\")\n",
        "\n",
        "# turn data into dataframe\n",
        "df = pd.read_csv('symptoms2_medcab3.csv')\n",
        "\n",
        "# Part 1\n",
        "# maybe make a function to perform the last few steps\n",
        "# a function to calculate_user_text_embedding\n",
        "# to save the embedding value in session memory\n",
        "user_input_embedding2 = 0\n",
        "\n",
        "def calculate_user_text_embedding(input, user_input_embedding2):\n",
        "\n",
        "    # setting a string of two sentences for the algo to compare\n",
        "    sentences = [input]\n",
        "\n",
        "    # calculating embedding for both user_entered_text and for features\n",
        "    with basilica.Connection('36a370e3-becb-99f5-93a0-a92344e78eab') as c:\n",
        "        user_input_embedding2 = list(c.embed_sentences(sentences))\n",
        "    \n",
        "    return user_input_embedding2\n",
        "\n",
        "# run the function to save the embedding value in session memory\n",
        "user_input_embedding2 = calculate_user_text_embedding(user_input_symptom, user_input_embedding2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# part 2\n",
        "score = 0\n",
        "\n",
        "def score_user_input_from_stored_embedding_from_stored_values(input, score, row1, user_input_embedding2):\n",
        "\n",
        "    # obtains pre-calculated values from a pickled dataframe of arrays\n",
        "    embedding_stored2 = unpickled_df_test2.loc[row1, 0]\n",
        "    \n",
        "    # calculates the similarity of user_text vs. product description\n",
        "    score = 1 - spatial.distance.cosine(embedding_stored2, user_input_embedding2)\n",
        "\n",
        "    # returns a variable that can be used outside of the function\n",
        "    return score\n",
        "\n",
        "\n",
        "\n",
        "# Part 3\n",
        "for i in range(2351):\n",
        "    # calls the function to set the value of 'score'\n",
        "    # which is the score of the user input\n",
        "    score = score_user_input_from_stored_embedding_from_stored_values(user_input_symptom, score, i, user_input_embedding2)\n",
        "    \n",
        "    #stores the score in the dataframe\n",
        "    df.loc[i,'score'] = score\n",
        "\n",
        "# Part 4: returns all data for the top 5 results as a json obj\n",
        "df_big_json = df['score'].sort_values(ascending=False)\n",
        "df_big_json = df.copy()\n",
        "df_big_json = df_big_json[:5]\n",
        "#df_big_json = df_big_json.to_json(orient='columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKMQuxi-uTnd",
        "colab_type": "code",
        "outputId": "9653f89c-45ca-4a50-9152-bc786d685b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        }
      },
      "source": [
        "df.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Strain</th>\n",
              "      <th>Type</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Effects</th>\n",
              "      <th>Flavor</th>\n",
              "      <th>Description</th>\n",
              "      <th>symptoms_diseases</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>100-Og</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Creative,Energetic,Tingly,Euphoric,Relaxed</td>\n",
              "      <td>Earthy,Sweet,Citrus</td>\n",
              "      <td>$100 OG is a 50/50 hybrid strain that packs a ...</td>\n",
              "      <td>ms, pain, pain, spasticity,</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Strain  ...             symptoms_diseases  score\n",
              "0           0  100-Og  ...  ms, pain, pain, spasticity,     NaN\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqp-MxdKup1b",
        "colab_type": "code",
        "outputId": "db1326be-d004-4f0b-acd0-0b4376fb2044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "df_big_json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Strain</th>\n",
              "      <th>Type</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Effects</th>\n",
              "      <th>Flavor</th>\n",
              "      <th>Description</th>\n",
              "      <th>symptoms_diseases</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>100-Og</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Creative,Energetic,Tingly,Euphoric,Relaxed</td>\n",
              "      <td>Earthy,Sweet,Citrus</td>\n",
              "      <td>$100 OG is a 50/50 hybrid strain that packs a ...</td>\n",
              "      <td>ms, pain, pain, spasticity,</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>98-White-Widow</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.7</td>\n",
              "      <td>Relaxed,Aroused,Creative,Happy,Energetic</td>\n",
              "      <td>Flowery,Violet,Diesel</td>\n",
              "      <td>The ‘98 Aloha White Widow is an especially pot...</td>\n",
              "      <td>spasticity,</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1024</td>\n",
              "      <td>sativa</td>\n",
              "      <td>4.4</td>\n",
              "      <td>Uplifted,Happy,Relaxed,Energetic,Creative</td>\n",
              "      <td>Spicy/Herbal,Sage,Woody</td>\n",
              "      <td>1024 is a sativa-dominant hybrid bred in Spain...</td>\n",
              "      <td>pain, pain, spasticity,</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>13-Dawgs</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.2</td>\n",
              "      <td>Tingly,Creative,Hungry,Relaxed,Uplifted</td>\n",
              "      <td>Apricot,Citrus,Grapefruit</td>\n",
              "      <td>13 Dawgs is a hybrid of G13 and Chemdawg genet...</td>\n",
              "      <td>appetite, appetite, depression, spasticity,</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>24K-Gold</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.6</td>\n",
              "      <td>Happy,Relaxed,Euphoric,Uplifted,Talkative</td>\n",
              "      <td>Citrus,Earthy,Orange</td>\n",
              "      <td>Also known as Kosher Tangie, 24k Gold is a 60%...</td>\n",
              "      <td>spasticity,</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... score\n",
              "0           0  ...   NaN\n",
              "1           1  ...   NaN\n",
              "2           2  ...   NaN\n",
              "3           3  ...   NaN\n",
              "4           4  ...   NaN\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmCpEXnBvs97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inflamation\n",
        "headaches\n",
        "fibromyalgia (not on state listing), \n",
        "arthritis\n",
        "pain\n",
        "epilepsy\n",
        "depression\n",
        "ptsd\n",
        "cancer\n",
        "appetite\n",
        "ms\n",
        "Multiple Sclerosis\n",
        "glaucoma\n",
        "anorexia\n",
        "nausia\n",
        "eating disorder\n",
        "anziety\n",
        "panic attack\n",
        "HIV / AIDS\n",
        "Spinal Cord\n",
        "IBD\n",
        "End of Life Care\n",
        "Insomnia\n",
        "appetite\n",
        "appetite loss (in addition to just 'appetite')\n",
        "peripheral neuropathy\n",
        "cachexia or wasting syndrome\n",
        "spasticity\n",
        "migraines"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}